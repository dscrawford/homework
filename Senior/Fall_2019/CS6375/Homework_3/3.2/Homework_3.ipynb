{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "# Cross validation will be used so test set is not always defined.\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "Xtrain, ytrain = X[:60000], y[:60000]\n",
    "Xtest, ytest = X[:60000], y[:60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imageSize = 28\n",
    "numImages = 70000\n",
    "\n",
    "data = X\n",
    "data = data.reshape(numImages, imageSize, imageSize, 1)\n",
    "\n",
    "image = np.array(data[10]).squeeze()\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'kernel': ('linear', 'rbf', 'poly', 'sigmoid'), 'C': [1, 5, 10]}\n",
    "svc = SVC(gamma = 'scale', cache_size = 1024, max_iter = 500, shrinking = True)\n",
    "clf = GridSearchCV(estimator = svc, param_grid = parameters, n_jobs = 8)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,param in enumerate(clf.cv_results_['params']):\n",
    "    print str(param) + str(': ') + str(1 - clf.cv_results_['mean_test_score'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.conda/envs/csgrads1/lib/python2.7/site-packages/sklearn/model_selection/_split.py:2052: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/daniel/.conda/envs/csgrads1/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=8,\n",
       "       param_grid={'alpha': [1, 10], 'activation': ['identity', 'logistic'], 'solver': ['lbfgs', 'sgd', 'adam'], 'hidden_layer_sizes': [50, 100, 150]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'activation': ['identity', 'logistic'], \n",
    "              'hidden_layer_sizes': [50, 100, 150],\n",
    "              'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "              'alpha': [1, 10]}\n",
    "mlp  = MLPClassifier()\n",
    "clf2 = GridSearchCV(estimator = mlp, param_grid = parameters, n_jobs=8)\n",
    "clf2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1, 'activation': 'identity', 'solver': 'lbfgs', 'hidden_layer_sizes': 50}: 0.11004285714285711\n",
      "{'alpha': 1, 'activation': 'identity', 'solver': 'sgd', 'hidden_layer_sizes': 50}: 0.9013857142857142\n",
      "{'alpha': 1, 'activation': 'identity', 'solver': 'adam', 'hidden_layer_sizes': 50}: 0.09618571428571432\n",
      "{'alpha': 1, 'activation': 'identity', 'solver': 'lbfgs', 'hidden_layer_sizes': 100}: 0.11761428571428567\n",
      "{'alpha': 1, 'activation': 'identity', 'solver': 'sgd', 'hidden_layer_sizes': 100}: 0.9013857142857142\n",
      "{'alpha': 1, 'activation': 'identity', 'solver': 'adam', 'hidden_layer_sizes': 100}: 0.10815714285714284\n",
      "{'alpha': 1, 'activation': 'identity', 'solver': 'lbfgs', 'hidden_layer_sizes': 150}: 0.11704285714285712\n",
      "{'alpha': 1, 'activation': 'identity', 'solver': 'sgd', 'hidden_layer_sizes': 150}: 0.9013857142857142\n",
      "{'alpha': 1, 'activation': 'identity', 'solver': 'adam', 'hidden_layer_sizes': 150}: 0.10054285714285716\n",
      "{'alpha': 10, 'activation': 'identity', 'solver': 'lbfgs', 'hidden_layer_sizes': 50}: 0.10925714285714283\n",
      "{'alpha': 10, 'activation': 'identity', 'solver': 'sgd', 'hidden_layer_sizes': 50}: 0.9013857142857142\n",
      "{'alpha': 10, 'activation': 'identity', 'solver': 'adam', 'hidden_layer_sizes': 50}: 0.08889999999999998\n",
      "{'alpha': 10, 'activation': 'identity', 'solver': 'lbfgs', 'hidden_layer_sizes': 100}: 0.11668571428571428\n",
      "{'alpha': 10, 'activation': 'identity', 'solver': 'sgd', 'hidden_layer_sizes': 100}: 0.9013857142857142\n",
      "{'alpha': 10, 'activation': 'identity', 'solver': 'adam', 'hidden_layer_sizes': 100}: 0.10070000000000001\n",
      "{'alpha': 10, 'activation': 'identity', 'solver': 'lbfgs', 'hidden_layer_sizes': 150}: 0.11705714285714286\n",
      "{'alpha': 10, 'activation': 'identity', 'solver': 'sgd', 'hidden_layer_sizes': 150}: 0.9013857142857142\n",
      "{'alpha': 10, 'activation': 'identity', 'solver': 'adam', 'hidden_layer_sizes': 150}: 0.09809999999999997\n",
      "{'alpha': 1, 'activation': 'logistic', 'solver': 'lbfgs', 'hidden_layer_sizes': 50}: 0.07497142857142858\n",
      "{'alpha': 1, 'activation': 'logistic', 'solver': 'sgd', 'hidden_layer_sizes': 50}: 0.05610000000000004\n",
      "{'alpha': 1, 'activation': 'logistic', 'solver': 'adam', 'hidden_layer_sizes': 50}: 0.06768571428571424\n",
      "{'alpha': 1, 'activation': 'logistic', 'solver': 'lbfgs', 'hidden_layer_sizes': 100}: 0.05501428571428568\n",
      "{'alpha': 1, 'activation': 'logistic', 'solver': 'sgd', 'hidden_layer_sizes': 100}: 0.04690000000000005\n",
      "{'alpha': 1, 'activation': 'logistic', 'solver': 'adam', 'hidden_layer_sizes': 100}: 0.06161428571428573\n",
      "{'alpha': 1, 'activation': 'logistic', 'solver': 'lbfgs', 'hidden_layer_sizes': 150}: 0.04590000000000005\n",
      "{'alpha': 1, 'activation': 'logistic', 'solver': 'sgd', 'hidden_layer_sizes': 150}: 0.04297142857142855\n",
      "{'alpha': 1, 'activation': 'logistic', 'solver': 'adam', 'hidden_layer_sizes': 150}: 0.057842857142857196\n",
      "{'alpha': 10, 'activation': 'logistic', 'solver': 'lbfgs', 'hidden_layer_sizes': 50}: 0.07347142857142852\n",
      "{'alpha': 10, 'activation': 'logistic', 'solver': 'sgd', 'hidden_layer_sizes': 50}: 0.07908571428571431\n",
      "{'alpha': 10, 'activation': 'logistic', 'solver': 'adam', 'hidden_layer_sizes': 50}: 0.09427142857142856\n",
      "{'alpha': 10, 'activation': 'logistic', 'solver': 'lbfgs', 'hidden_layer_sizes': 100}: 0.05324285714285715\n",
      "{'alpha': 10, 'activation': 'logistic', 'solver': 'sgd', 'hidden_layer_sizes': 100}: 0.0636714285714286\n",
      "{'alpha': 10, 'activation': 'logistic', 'solver': 'adam', 'hidden_layer_sizes': 100}: 0.08954285714285715\n",
      "{'alpha': 10, 'activation': 'logistic', 'solver': 'lbfgs', 'hidden_layer_sizes': 150}: 0.043742857142857194\n",
      "{'alpha': 10, 'activation': 'logistic', 'solver': 'sgd', 'hidden_layer_sizes': 150}: 0.05611428571428567\n",
      "{'alpha': 10, 'activation': 'logistic', 'solver': 'adam', 'hidden_layer_sizes': 150}: 0.08438571428571429\n"
     ]
    }
   ],
   "source": [
    "for i,param in enumerate(clf2.cv_results_['params']):\n",
    "    print str(param) + str(': ') + str(1 - clf2.cv_results_['mean_test_score'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1      112970.7482            1.96m\n",
      "         2       97079.5692            1.95m\n",
      "         3       85491.7687            1.92m\n",
      "         4       76592.8425            1.85m\n",
      "         5       69139.7263            1.82m\n",
      "         6       62394.7767            1.82m\n",
      "         7       56924.4203            1.80m\n",
      "         8       52116.4377            1.78m\n",
      "         9       48025.8667            1.75m\n",
      "        10       44579.7969            1.74m\n",
      "        20       24740.1806            1.61m\n",
      "        30       16555.2774            1.39m\n",
      "        40       12261.8780            1.18m\n",
      "        50        9636.3732           58.86s\n",
      "        60        7861.6798           46.82s\n",
      "        70        6514.5875           35.10s\n",
      "        80        5506.5778           23.35s\n",
      "        90        4688.2438           11.62s\n",
      "       100        4026.1793            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      116525.0236            1.45m\n",
      "         2      102413.0507            1.33m\n",
      "         3       91973.0158            1.30m\n",
      "         4       83565.1637            1.30m\n",
      "         5       76578.7153            1.28m\n",
      "         6       70190.9135            1.28m\n",
      "         7       65091.0198            1.26m\n",
      "         8       60555.6668            1.25m\n",
      "         9       56518.9779            1.23m\n",
      "        10       53102.6932            1.22m\n",
      "        20       31340.1869            1.08m\n",
      "        30       22172.7305           56.79s\n",
      "        40       17290.1731           48.08s\n",
      "        50       14192.7768           39.71s\n",
      "        60       12039.0993           31.63s\n",
      "        70       10467.8791           23.64s\n",
      "        80        9242.3967           15.62s\n",
      "        90        8229.7727            7.79s\n",
      "       100        7452.3459            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      121637.0556           52.48s\n",
      "         2      111267.0273           53.47s\n",
      "         3      101367.8152           52.91s\n",
      "         4       93003.6813           51.99s\n",
      "         5       86053.9906           51.28s\n",
      "         6       79911.4387           50.97s\n",
      "         7       75121.1390           50.13s\n",
      "         8       70214.2459           50.19s\n",
      "         9       66495.2757           49.59s\n",
      "        10       62884.6324           49.13s\n",
      "        20       40497.1685           43.29s\n",
      "        30       30164.1931           37.23s\n",
      "        40       24155.6028           32.03s\n",
      "        50       20457.4210           26.70s\n",
      "        60       17828.1190           21.19s\n",
      "        70       15978.7470           15.76s\n",
      "        80       14448.5542           10.51s\n",
      "        90       13243.6576            5.22s\n",
      "       100       12230.5096            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      127817.2578           31.14s\n",
      "         2      119537.8869           30.93s\n",
      "         3      111702.9163           30.11s\n",
      "         4      105299.4886           30.06s\n",
      "         5       99508.7167           29.98s\n",
      "         6       94021.7024           29.88s\n",
      "         7       89535.2496           29.67s\n",
      "         8       85105.4498           29.42s\n",
      "         9       81199.1432           29.14s\n",
      "        10       77697.4755           28.71s\n",
      "        20       54843.8785           25.62s\n",
      "        30       43152.7414           22.35s\n",
      "        40       35828.9520           19.07s\n",
      "        50       31188.6262           15.78s\n",
      "        60       27868.7761           12.57s\n",
      "        70       25332.5600            9.41s\n",
      "        80       23306.9704            6.23s\n",
      "        90       21696.5768            3.10s\n",
      "       100       20271.2111            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      133168.1601           16.95s\n",
      "         2      128125.8999           16.82s\n",
      "         3      124780.1274           16.79s\n",
      "         4      121045.1771           16.65s\n",
      "         5      117692.8256           16.46s\n",
      "         6      114003.8502           16.31s\n",
      "         7      111379.2698           16.12s\n",
      "         8      107985.2443           15.95s\n",
      "         9      104781.5662           15.76s\n",
      "        10      102052.7378           15.58s\n",
      "        20       82119.0352           13.83s\n",
      "        30       68500.8731           12.09s\n",
      "        40       59244.9319           10.38s\n",
      "        50       52084.7878            8.65s\n",
      "        60       47355.2635            6.92s\n",
      "        70       43493.3085            5.19s\n",
      "        80       40407.1215            3.49s\n",
      "        90       37918.1359            1.76s\n",
      "       100       35810.3757            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='mse', init=None, learning_rate=0.1,\n",
       "              loss='deviance', max_depth=1, max_features='sqrt',\n",
       "              max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "              min_impurity_split=None, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, n_iter_no_change=None, presort='auto',\n",
       "              random_state=None, subsample=1.0, tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gbc = GradientBoostingClassifier(loss='deviance',criterion='mse', verbose=1, max_depth=5, max_features = 'sqrt')\n",
    "gbc.fit(Xtrain, ytrain)\n",
    "\n",
    "gbc2 = GradientBoostingClassifier(loss='deviance',criterion='mse', verbose=1, max_depth=4, max_features = 'sqrt')\n",
    "gbc2.fit(Xtrain, ytrain)\n",
    "\n",
    "gbc3 = GradientBoostingClassifier(loss='deviance',criterion='mse', verbose=1, max_depth=3, max_features = 'sqrt')\n",
    "gbc3.fit(Xtrain, ytrain)\n",
    "\n",
    "gbc4 = GradientBoostingClassifier(loss='deviance',criterion='mse', verbose=1, max_depth=2,\n",
    "                                  max_features = 'sqrt')\n",
    "gbc4.fit(Xtrain, ytrain)\n",
    "\n",
    "gbc5 = GradientBoostingClassifier(loss='deviance',criterion='mse', verbose=1, max_depth=1,\n",
    "                                  max_features = 'sqrt')\n",
    "gbc5.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1      112655.1313            1.94m\n",
      "         2       96983.7541            1.93m\n",
      "         3       85836.5818            1.93m\n",
      "         4       76276.4675            1.91m\n",
      "         5       68780.9565            1.88m\n",
      "         6       62323.4338            1.86m\n",
      "         7       56733.8442            1.82m\n",
      "         8       52084.8908            1.79m\n",
      "         9       48239.3121            1.77m\n",
      "        10       44734.2426            1.75m\n",
      "        20       24529.4047            1.54m\n",
      "        30       16616.2694            1.35m\n",
      "        40       12361.9295            1.17m\n",
      "        50        9708.4288           58.04s\n",
      "        60        7830.4731           46.43s\n",
      "        70        6566.4144           34.67s\n",
      "        80        5563.9196           22.88s\n",
      "        90        4777.2497           11.39s\n",
      "       100        4127.4252            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      118445.2436            1.31m\n",
      "         2      104435.8815            1.31m\n",
      "         3       93736.0919            1.28m\n",
      "         4       84352.9261            1.26m\n",
      "         5       77116.4503            1.24m\n",
      "         6       70673.8381            1.22m\n",
      "         7       65251.0232            1.20m\n",
      "         8       60651.6262            1.19m\n",
      "         9       56482.6076            1.18m\n",
      "        10       52691.9048            1.17m\n",
      "        20       31472.5474            1.04m\n",
      "        30       22337.9032           54.31s\n",
      "        40       17342.1437           46.51s\n",
      "        50       14254.7230           38.69s\n",
      "        60       12088.1528           30.83s\n",
      "        70       10483.9979           22.93s\n",
      "        80        9270.6006           15.19s\n",
      "        90        8291.3545            7.56s\n",
      "       100        7454.4441            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      122303.1600           50.30s\n",
      "         2      111038.3201           48.98s\n",
      "         3      101363.0074           48.36s\n",
      "         4       93849.8896           48.05s\n",
      "         5       86743.3446           47.93s\n",
      "         6       81386.5235           47.96s\n",
      "         7       76103.3505           47.55s\n",
      "         8       71378.2028           47.15s\n",
      "         9       67470.4403           46.75s\n",
      "        10       63729.7281           46.71s\n",
      "        20       40934.0094           41.37s\n",
      "        30       30289.9171           35.92s\n",
      "        40       24314.0820           30.62s\n",
      "        50       20609.2228           25.38s\n",
      "        60       18124.3936           20.20s\n",
      "        70       16212.5761           15.08s\n",
      "        80       14694.3043            9.99s\n",
      "        90       13508.1817            4.97s\n",
      "       100       12503.9868            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      127165.9487           30.77s\n",
      "         2      117625.6507           31.11s\n",
      "         3      110331.1758           30.43s\n",
      "         4      104131.5470           29.85s\n",
      "         5       98334.3347           29.57s\n",
      "         6       93781.6367           29.23s\n",
      "         7       89733.9237           28.69s\n",
      "         8       85427.5153           28.32s\n",
      "         9       82026.9938           28.06s\n",
      "        10       78642.2407           27.77s\n",
      "        20       56348.5591           24.76s\n",
      "        30       43723.1815           21.74s\n",
      "        40       36080.4585           18.80s\n",
      "        50       31182.6028           15.64s\n",
      "        60       27890.0381           12.44s\n",
      "        70       25289.1109            9.28s\n",
      "        80       23282.3876            6.16s\n",
      "        90       21605.6829            3.07s\n",
      "       100       20216.6073            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      135517.3877            1.83m\n",
      "         2      132961.7817            1.84m\n",
      "         3      130501.6054            1.85m\n",
      "         4      128227.9017            1.83m\n",
      "         5      125930.3363            1.81m\n",
      "         6      123748.4377            1.80m\n",
      "         7      121641.8817            1.79m\n",
      "         8      119618.4961            1.77m\n",
      "         9      117781.8828            1.75m\n",
      "        10      116022.1139            1.73m\n",
      "        20      100212.7047            1.54m\n",
      "        30       88372.7831            1.35m\n",
      "        40       78852.0682            1.16m\n",
      "        50       71051.3392           57.89s\n",
      "        60       64351.7862           46.32s\n",
      "        70       58686.7172           34.76s\n",
      "        80       53737.4742           23.15s\n",
      "        90       49485.5647           11.58s\n",
      "       100       45726.6628            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.01, loss='deviance', max_depth=5,\n",
       "              max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc7 = GradientBoostingClassifier(loss='deviance',criterion='friedman_mse', verbose=1, max_depth=5,\n",
    "                                  max_features = 'sqrt')\n",
    "gbc7.fit(Xtrain, ytrain)\n",
    "\n",
    "gbc7 = GradientBoostingClassifier(loss='deviance',criterion='friedman_mse', verbose=1, max_depth=4,\n",
    "                                  max_features = 'sqrt')\n",
    "gbc7.fit(Xtrain, ytrain)\n",
    "\n",
    "gbc8 = GradientBoostingClassifier(loss='deviance',criterion='friedman_mse', verbose=1, max_depth=3,\n",
    "                                  max_features = 'sqrt')\n",
    "gbc8.fit(Xtrain, ytrain)\n",
    "\n",
    "gbc9 = GradientBoostingClassifier(loss='deviance',criterion='friedman_mse', verbose=1, max_depth=2,\n",
    "                                  max_features = 'sqrt')\n",
    "gbc9.fit(Xtrain, ytrain)\n",
    "\n",
    "gbc10 = GradientBoostingClassifier(loss='deviance',criterion='friedman_mse', verbose=1, max_depth=5,\n",
    "                                  learning_rate = 0.01, max_features = 'sqrt')\n",
    "gbc10.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse with max depth 5 error rate: 0.9889333333333333\n",
      "mse with max depth 4 error rate: 0.9717\n",
      "mse with max depth 3 error rate: 0.9501333333333334\n",
      "mae with max depth 2 error rate: 0.9145166666666666\n",
      "mae with max depth 1 error rate: 0.8560166666666666\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gb7' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-751f153bc1a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'mae with max depth 2 error rate: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbc4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'mae with max depth 1 error rate: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbc5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m'friedman_mse with max depth 5 error rate: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgb7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'friedman_mse with max depth 4 error rate: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbc8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'friedman_mse with max depth 3 error rate: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbc9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gb7' is not defined"
     ]
    }
   ],
   "source": [
    "print 'mse with max depth 5 error rate: ' + str(gbc.score(Xtest,ytest))\n",
    "print 'mse with max depth 4 error rate: ' + str(gbc2.score(Xtest,ytest))\n",
    "print 'mse with max depth 3 error rate: ' + str(gbc3.score(Xtest,ytest))\n",
    "print 'mae with max depth 2 error rate: ' + str(gbc4.score(Xtest,ytest))\n",
    "print 'mae with max depth 1 error rate: ' + str(gbc5.score(Xtest,ytest))\n",
    "print 'friedman_mse with max depth 5 error rate: ' + str(gb7.score(Xtest,ytest))\n",
    "print 'friedman_mse with max depth 4 error rate: ' + str(gbc8.score(Xtest,ytest))\n",
    "print 'friedman_mse with max depth 3 error rate: ' + str(gbc9.score(Xtest,ytest))\n",
    "print 'friedman_mse with max depth 2 error rate: ' + str(gbc9.score(Xtest,ytest))\n",
    "print 'friedman_mse with max depth 5 and learning rate 0.01 error rate: ' + str(gbc10.score(Xtest,ytest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
