{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BELOW CODE WAS IMPLEMENTED BY John Reid in pybool package\n",
    "# https://github.com/JohnReid/pybool/blob/master/python/pybool/chow_liu_trees.py\n",
    "#\n",
    "# The code has been pasted here because csgrads1 was having issues installing pybool\n",
    "# Add one laplace smoothing has also been included.\n",
    "# Also, the code below has some minor modifications.\n",
    "\n",
    "def marginal_distribution(X, u):\n",
    "    \"\"\"\n",
    "    Return the marginal distribution for the u'th features of the data points, X.\n",
    "    \"\"\"\n",
    "    values = defaultdict(float)\n",
    "    s = 1. / len(X)\n",
    "    for x in X:\n",
    "        values[x[u]] += s\n",
    "    return values\n",
    "\n",
    "\n",
    "\n",
    "def marginal_pair_distribution(X, u, v):\n",
    "    \"\"\"\n",
    "    Return the marginal distribution for the u'th and v'th features of the data points, X.\n",
    "    \"\"\"\n",
    "    if u > v:\n",
    "        u, v = v, u\n",
    "    values = defaultdict(float)\n",
    "    s = 1. / len(X)\n",
    "    for x in X:\n",
    "        values[(x[u], x[v])] += s\n",
    "    return values\n",
    "\n",
    "\n",
    "\n",
    "def calculate_mutual_information(X, u, v):\n",
    "    \"\"\"\n",
    "    X are the data points.\n",
    "    u and v are the indices of the features to calculate the mutual information for.\n",
    "    \"\"\"\n",
    "    if u > v:\n",
    "        u, v = v, u\n",
    "    marginal_u = marginal_distribution(X, u)\n",
    "    marginal_v = marginal_distribution(X, v)\n",
    "    marginal_uv = marginal_pair_distribution(X, u, v)\n",
    "    I = 0.\n",
    "    for x_u, p_x_u in marginal_u.iteritems():\n",
    "        for x_v, p_x_v in marginal_v.iteritems():\n",
    "            if (x_u, x_v) in marginal_uv:\n",
    "                p_x_uv = marginal_uv[(x_u, x_v)]\n",
    "                I += p_x_uv * (np.log2(p_x_uv) - np.log2(p_x_u) - np.log2(p_x_v))\n",
    "    return I\n",
    "\n",
    "\n",
    "def build_chow_liu_tree(X, n):\n",
    "    \"\"\"\n",
    "    Build a Chow-Liu tree from the data, X. n is the number of features. The weight on each edge is\n",
    "    the negative of the mutual information between those features. The tree is returned as a networkx\n",
    "    object.\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    for v in xrange(n):\n",
    "        G.add_node(v)\n",
    "        for u in xrange(v):\n",
    "            G.add_edge(u, v, weight=-calculate_mutual_information(X, u, v))\n",
    "    T = nx.minimum_spanning_tree(G)\n",
    "    return T\n",
    "\n",
    "# BELOW CODE MODIFIED BY ME TO WORK WITH MIXTURE TREES, ORIGINALLY MADE BY John Reid (cited above)\n",
    "def build_chow_liu_tree_mt(X, n, P):\n",
    "    \"\"\"\n",
    "    Build a Chow-Liu tree from the data, X. n is the number of features. The weight on each edge is\n",
    "    the negative of the mutual information between those features. The tree is returned as a networkx\n",
    "    object.\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    for v in xrange(n):\n",
    "        G.add_node(v)\n",
    "        for u in xrange(v):\n",
    "            G.add_edge(u, v, weight=-calculate_mutual_information_mt(X, u, v, P))\n",
    "    T = nx.minimum_spanning_tree(G)\n",
    "    return T\n",
    "\n",
    "def marginal_distribution_mt(X, u, P):\n",
    "    \"\"\"\n",
    "    Return the marginal distribution for the u'th features of the data points, X.\n",
    "    \"\"\"\n",
    "    values = defaultdict(float)\n",
    "    s = 1. / len(X)\n",
    "    for x in X:\n",
    "        values[x[u]] += s\n",
    "    for i,x in enumerate(X):\n",
    "        values[x[u]] *= P[i]\n",
    "    return values\n",
    "\n",
    "def marginal_pair_distribution_mt(X, u, v, P):\n",
    "    \"\"\"\n",
    "    Return the marginal distribution for the u'th and v'th features of the data points, X.\n",
    "    \"\"\"\n",
    "    if u > v:\n",
    "        u, v = v, u\n",
    "    values = defaultdict(float)\n",
    "    s = 1. / len(X)\n",
    "    for x in X:\n",
    "        values[(x[u], x[v])] += s\n",
    "    for i,x in enumerate(X):\n",
    "        values[x[u]] *= P[i]\n",
    "    return values\n",
    "\n",
    "def calculate_mutual_information_mt(X, u, v, P):\n",
    "    \"\"\"\n",
    "    X are the data points.\n",
    "    u and v are the indices of the features to calculate the mutual information for.\n",
    "    \"\"\"\n",
    "    if u > v:\n",
    "        u, v = v, u\n",
    "    marginal_u = marginal_distribution_mt(X, u, P)\n",
    "    marginal_v = marginal_distribution_mt(X, v, P)\n",
    "    marginal_uv = marginal_pair_distribution_mt(X, u, v, P)\n",
    "    I = 0.\n",
    "    for x_u, p_x_u in marginal_u.iteritems():\n",
    "        for x_v, p_x_v in marginal_v.iteritems():\n",
    "            if (x_u, x_v) in marginal_uv:\n",
    "                p_x_uv = marginal_uv[(x_u, x_v)]\n",
    "                I += p_x_uv * (np.log2(p_x_uv) - np.log2(p_x_u) - np.log2(p_x_v))\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./small-10-datasets/\"\n",
    "data_titles = ['accidents', 'baudio', 'bnetflix', 'dna', 'jester', 'kdd', 'msnbc',\n",
    "              'nltcs', 'plants', 'r52']\n",
    "test  = dict()\n",
    "train = dict()\n",
    "valid = dict()\n",
    "\n",
    "for title in data_titles:\n",
    "    test[title]  = np.loadtxt(data_dir + title + '.test.data', delimiter=',')\n",
    "    train[title] = np.loadtxt(data_dir + title + '.ts.data', delimiter=',')\n",
    "    valid[title] = np.loadtxt(data_dir + title + '.valid.data', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Likelihood\n",
    "def LL(p):\n",
    "    return np.sum(np.log2(p))\n",
    "\n",
    "def AVG_LL(P):\n",
    "    return sum([LL(p) for p in P]) / len(P)\n",
    "\n",
    "# Log Sum Exponent\n",
    "def lse(a):\n",
    "    m = max(a)\n",
    "    return np.log2(np.sum(np.power(2., a - m))) + m\n",
    "\n",
    "def Split_Tree(T, k):\n",
    "    split = [i for i in range(0, len(T), int(len(T) / k))]\n",
    "    return [T[range(split[i],len(T) if i == k -1 else split[i+1])] for i in range(k)]\n",
    "\n",
    "# Transforms MST into a DAG, and then finds associated probabilities as well.\n",
    "def Create_Network(MST, T):\n",
    "    n = len(MST)\n",
    "    T = np.transpose(T)\n",
    "    network = [{} for i in range(n)]\n",
    "    root = 0\n",
    "\n",
    "    p = (sum(T[root] == 1) + 1) / (len(T[root]) + 2)\n",
    "    network[root] = {root : [1 - p, p]}\n",
    "    children = np.ndarray.flatten(np.argwhere(np.transpose(MST[root]) != 0))\n",
    "    parents = {root : children}\n",
    "    for c in children:\n",
    "        MST[c][root] = 0.\n",
    "\n",
    "    while (len(parents) != 0):\n",
    "        newParents   = {}\n",
    "        for parent in parents:\n",
    "            children = parents[parent]\n",
    "            for c in children:\n",
    "                # Remove edge, make directed\n",
    "                p = [(sum(T[c][T[parent] == 0] == 1) + 1) / (sum(T[parent] == 0) + 2),\n",
    "                     (sum(T[c][T[parent] == 1] == 1) + 1) / (sum(T[parent] == 1) + 2)]\n",
    "                network[c].update({parent : [1 - p[0], p[0], 1 - p[1], p[1]]})\n",
    "                cc = np.ndarray.flatten(np.argwhere(np.transpose(MST[c]) != 0))\n",
    "                for child in cc:\n",
    "                    MST[child][c] = 0\n",
    "                if (len(children) != 0):\n",
    "                    newParents.update({c : cc})\n",
    "        parents = newParents    \n",
    "    return network;\n",
    "\n",
    "# Predicts a network generated from above.\n",
    "def Predict_Network(N, test):\n",
    "    all_predictions = []\n",
    "    for t in test:\n",
    "        predictions = []\n",
    "        for i in range(len(N)):\n",
    "            probs = []\n",
    "            for k in N[i].keys():\n",
    "                if(k == i):\n",
    "                    probs.append(N[i][k][0] if t[i] == 0 else N[i][k][1])\n",
    "                else:\n",
    "                    if (t[k] == 0):\n",
    "                        probs.append(N[i][k][0] if t[i] == 0 else N[i][k][1])\n",
    "                    else:\n",
    "                        probs.append(N[i][k][2] if t[i] == 0 else N[i][k][3])\n",
    "            predictions.append(np.product(probs))\n",
    "        all_predictions.append(predictions)\n",
    "    return np.array(all_predictions)\n",
    "\n",
    "def Predict_Mixture(M, test):\n",
    "    N  = M[1]\n",
    "    pi = M[0]\n",
    "    n = len(pi)\n",
    "    predictions = []\n",
    "    for i in range(n):\n",
    "        predictions.append(pi[i] * Predict_Network(N[i], test))\n",
    "    return np.sum(predictions, axis=0)\n",
    "    \n",
    "# Bayesian Network, No edges Algorithm\n",
    "# Takes in a dataset of binary variables and takes a test set of binary variables.\n",
    "def BN_NE(T, test):\n",
    "    cols = np.transpose(T)\n",
    "    n    = len(cols)\n",
    "    p_1 = np.array([(sum(cols[i] == 1) + 1) / (len(cols[i]) + 2) for i in range(n)])\n",
    "    return np.array([[p_1[+i] if ti == 0 else 1 - p_1[i] for i, ti in enumerate(t)] for t in test])\n",
    "\n",
    "# Bayesian Network, Chow-Liu Algorithm\n",
    "# Returns a data structure in the form of a Bayesian Network with probabilities pre-computed inside.\n",
    "def BN_CL(T):\n",
    "    n = len(T[0])\n",
    "    CLT = Create_Network(np.array(nx.adjacency_matrix(build_chow_liu_tree(T, n)).todense()), T)\n",
    "    return CLT\n",
    "\n",
    "# Bayesian Network, Chow-Liu Algorithm using mixture trees\n",
    "# Returns a data structure in the form of a Bayesian Network with probabilities pre-computed inside.\n",
    "def BN_CL_MT(T, P):\n",
    "    n = len(T[0])\n",
    "    CLT = Create_Network(np.array(nx.adjacency_matrix(build_chow_liu_tree_mt(T, n, P)).todense()), T)\n",
    "    return CLT\n",
    "\n",
    "\n",
    "# Mixtures of Tree Bayesian networks using EM\n",
    "def MT_BN(T, k):\n",
    "    V = T[range(0, int(len(T) / 10))]\n",
    "    T     = T[range(int(len(T) / 10), len(T))]\n",
    "    return EM(T, k, 10)\n",
    "\n",
    "# Expectation Maximization\n",
    "def EM(T, m, max_iter):\n",
    "    split = Split_Tree(T, m)\n",
    "    r = np.array([random.random() for i in range(m)]).astype(np.float64)\n",
    "    pi = [i / sum(r) for i in r]\n",
    "    pk = [[random.random() for j in range(m)] for i in range(len(T))]\n",
    "    pk = [[pk[i][j] / sum(pk[i]) for j in range(m)] for i in range(len(T))]\n",
    "    N = [BN_CL_MT(T, np.transpose(pk)[i]) for i,s in enumerate(split)]\n",
    "    \n",
    "    \n",
    "    prevPi = []\n",
    "    it = 0\n",
    "    while (prevPi != pi or it != max_iter):\n",
    "        # E-step\n",
    "        prevPi = pi\n",
    "        it += 1\n",
    "        \n",
    "        W = []\n",
    "        p = [[pi[k] * np.product(Predict_Network(N[k],[t])) for k in range(m)] for t in T]\n",
    "        yk = np.array([[p[i][k] / sum(p[i]) for k in range(m)] for i in range(len(T))])\n",
    "        rk = [sum(k) for k in np.transpose(yk)]\n",
    "        pk = [[yk[i][k] / rk[k] for k in range(m)] for i in range(len(T))]\n",
    "        \n",
    "        # M-step\n",
    "        pi = [rk[k] / sum(rk) for k in range(m)]\n",
    "        for k in range(m):\n",
    "            N[k] = BN_CL_MT(T, np.transpose(pk)[k])\n",
    "            \n",
    "    return [pi, N]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-303.09757458863464"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVG_LL(BN_NE(train['accidents'], test['accidents']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-47.88027600729854"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVG_LL(Predict_Network((BN_CL(T=train['accidents'])), test['accidents']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVG_LL(Predict_Mixture(MT_BN(train['accidents'], 5), test['accidents']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = MT_BN(train['accidents'][0:100],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-66.81791975350862"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVG_LL(Predict_Mixture(M, test['accidents']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
