{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import time, sys\n",
    "import math\n",
    "\n",
    "# Code made by Brain Khuu: https://stackoverflow.com/questions/3160699/python-progress-bar\n",
    "# update_progress() : Displays or updates a console progress bar\n",
    "## Accepts a float between 0 and 1. Any int will be converted to a float.\n",
    "## A value under 0 represents a 'halt'.\n",
    "## A value at 1 or bigger represents 100%\n",
    "def update_progress(progress):\n",
    "    \n",
    "    barLength = 10 # Modify this to change the length of the progress bar\n",
    "    status = \"\"\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "        status = \"error: progress var must be float\\r\\n\"\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "        status = \"\\nHalt...\\r\\n\"\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "        status = \"\\nDone...\\r\\n\"\n",
    "    block = int(round(barLength*progress))\n",
    "    text = \"\\rPercent: [{0}] {1}% {2}\".format( \"#\"*block + \"-\"*(barLength-block), progress*100, status)\n",
    "    sys.stdout.write(text)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/home/daniel/Documents/homework/Senior/Fall_2019/CS6375/Homework_2/Code/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condense multiple whitespaces into one, grab only alphabetic words, convert to lowercase\n",
    "# and return array of words.\n",
    "def getAllWordsFromString(words):\n",
    "    return re.sub('\\s+', ' ',re.sub('[^a-zA-Z1-9]+', ' ', words)).strip().lower().split(\" \")\n",
    "\n",
    "# getCountOfWords\n",
    "# Create a dictionary with the count of each word in a string.\n",
    "def getCountOfWords(words, allUniqueWords):\n",
    "    allUniqueWordsDict = { i : 0 for i in allUniqueWords }\n",
    "    counts = Counter(getAllWordsFromString(words))\n",
    "    counts = {k : v for k, v in dict(counts).items() if k in allUniqueWordsDict}\n",
    "    return mergeTwoDicts(allUniqueWordsDict, counts)\n",
    "\n",
    "#getBernoulliWords\n",
    "# Create a dictionary that shows the existence of words as 1 or 0.\n",
    "def getBernoulliWords(words, allUniqueWords):\n",
    "    counts = getCountOfWords(words, allUniqueWords)\n",
    "    #Transform counts into existense\n",
    "    return { k : (0 if v == 0 else 1) for k , v in counts.items()}\n",
    "        \n",
    "def getCountOfWordsWithProgressBar(words, allUniqueWords, progress):\n",
    "    progress = round(progress,3)\n",
    "    update_progress(progress)\n",
    "    return getCountOfWords(words, allUniqueWords)\n",
    "\n",
    "def getBernoulliWithProgressBar(words, allUniqueWords, progress):\n",
    "    progress = round(progress,3)\n",
    "    update_progress(progress)\n",
    "    return getBernoulliWords(words, allUniqueWords)\n",
    "\n",
    "#getProduct of Probabilities\n",
    "# returns the log probability sum of all of the elements based on bayes\n",
    "# works with both bernoulli and bag of words model\n",
    "def getProductOfProbabities(text, T):\n",
    "    featureSums = T.sum().loc[[w for w in getAllWordsFromString(text) if w in T.columns]]\n",
    "    totalWords  = T.sum().sum()\n",
    "    return np.log( (featureSums + 1) / (totalWords + len(T.columns))).sum()\n",
    "\n",
    "def mergeTwoDicts(x, y):\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayesOnModel(text, T):\n",
    "    p_0 = np.log(len(T[T['isSpam'] == 0]) / len(T)) + getProductOfProbabities(text, (T[T['isSpam'] == 0]).drop('isSpam', axis=1))\n",
    "    p_1 = np.log(len(T[T['isSpam'] == 1]) / len(T)) + getProductOfProbabities(text, (T[T['isSpam'] == 1]).drop('isSpam', axis=1))\n",
    "    return 0 if p_0 > p_1 else 1\n",
    "\n",
    "def MCAPUpdateWeights(T, learnRate, W):\n",
    "    changeW = learnRate * np.array([sum([T[x][i] * (y - (T[T['isSpam'] == 1][x].sum()) / T[x].sum())\n",
    "                    for i,y in enumerate(T['isSpam'])])\n",
    "               for x in ['a']])\n",
    "    \n",
    "    return W + changeW\n",
    "    \n",
    "def getDirectoryContents(dataDirectory):\n",
    "    contents = np.array([])\n",
    "    for fileName in os.listdir(dataDirectory):\n",
    "        contents = np.append(contents, [open(dataDirectory + fileName).read()])\n",
    "    return contents\n",
    "\n",
    "def getBagOfWordsDataFrame(data, allUniqueWords):\n",
    "    print \"Creating DataFrame with Bag Of Words as the feature...\"\n",
    "    attributes = set(allUniqueWords)\n",
    "    df = pd.DataFrame([getCountOfWordsWithProgressBar(d[1], attributes, i / (len(data) - 1))\n",
    "                       for i,d in enumerate(data)])\n",
    "    df.insert(0, 'isSpam', [d[0] for d in data])\n",
    "    return df\n",
    "\n",
    "def getBernoulliDataFrame(data, allUniqueWords):\n",
    "    print \"Creating DataFrame with Bernoulli model as the feature...\"\n",
    "    attributes = set(allUniqueWords)\n",
    "    df = pd.DataFrame([getBernoulliWithProgressBar(d[1], attributes, i / (len(data) - 1))\n",
    "                       for i,d in enumerate(data)])\n",
    "    df.insert(0, 'isSpam', [d[0] for d in data])\n",
    "    return df\n",
    "\n",
    "def getAccuracyOnNaiveBayes(Test, Train):\n",
    "    return sum(Test.apply(lambda x: naiveBayesOnModel(x['text'], Train) == x['isSpam'], axis=1)) / len(Test)    \n",
    "\n",
    "def PredictWithLR(T, W):\n",
    "    bias = W[0]\n",
    "    PY_1 = 1 / (1 + math.exp(bias + \n",
    "                             T.apply(lambda x: (T[x].sum() / T.sum().sum()) * W[x]).sum()))\n",
    "    PY_0 = 1 - PY_1\n",
    "    \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainHamData  = [[0,f] for f in getDirectoryContents(directory + \"train/ham/\")]\n",
    "trainSpamData = [[1,f] for f in getDirectoryContents(directory + \"train/spam/\")]\n",
    "allTrainData  = trainHamData + trainSpamData\n",
    "testHamData   = [[0,f] for f in getDirectoryContents(directory + \"test/ham/\")]\n",
    "testSpamData  = [[1,f] for f in getDirectoryContents(directory + \"test/spam/\")]\n",
    "allTestData   = pd.DataFrame(testHamData + testSpamData).rename(columns={0: 'isSpam', 1: 'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform all files into a single string.\n",
    "allTrainWords = ''.join([f[1] for f in allTrainData])\n",
    "#Retrieve all unique WORDS - Remove all words with numbers/punctuation and replace with space.\n",
    "allUniqueWords = np.unique(getAllWordsFromString(allTrainWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DataFrame with Bernoulli model as the feature...\n",
      "Percent: [##########] 100%  \n",
      "Done...\n",
      "Creating DataFrame with Bernoulli model as the feature...\n",
      "Percent: [##########] 100%  \n",
      "Done...\n",
      "Creating DataFrame with Bag Of Words as the feature...\n",
      "Percent: [##########] 100%  \n",
      "Done...\n",
      "Creating DataFrame with Bag Of Words as the feature...\n",
      "Percent: [##########] 100%  \n",
      "Done...\n"
     ]
    }
   ],
   "source": [
    "#Get a dataframe with bernoulli as the feature\n",
    "trainB = getBernoulliDataFrame(allTrainData, allUniqueWords)\n",
    "testB  = getBernoulliDataFrame(testHamData + testSpamData, allUniqueWords)\n",
    "#Get a dataframe with bag of words as a feature for training\n",
    "trainBOW = getBagOfWordsDataFrame(allTrainData, allUniqueWords)\n",
    "testBOW  = getBagOfWordsDataFrame(testHamData + testSpamData, allUniqueWords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9476987447698745"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Multinomial Bayes\n",
    "getAccuracyOnNaiveBayes(allTestData, trainBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8828451882845189"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Discrete bayes\n",
    "getAccuracyOnNaiveBayes(allTestData, trainB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def getProbYIsZero(scores):\n",
    "    return 1 / (1 + np.exp(-scores))\n",
    "\n",
    "def getProbYIsOne(scores):\n",
    "    return 1 - getProbYIsZero(scores)\n",
    "\n",
    "def getWeight(W, T):\n",
    "    predictions = getPredictions(W, T)\n",
    "    target      = T['isSpam']\n",
    "    attributes  = T.drop('isSpam', axis=1)\n",
    "    attributes.insert(0, 'x_0', 1)\n",
    "    gradient    = np.dot(attributes.T, target - predictions)\n",
    "    return gradient.astype(np.float64)\n",
    "\n",
    "def getLogLikelihood(W, T):\n",
    "    target = T['isSpam']\n",
    "    features = T.drop('isSpam', axis=1)\n",
    "    features.insert(0, 'isSpam', 1)\n",
    "    scores = np.dot(features, W)\n",
    "    return np.sum(target * scores - np.log(1 + np.exp(-scores)))\n",
    "\n",
    "def getPredictions(W, T):\n",
    "    features = T.drop('isSpam', axis=1)\n",
    "    features.insert(0, 'isSpam', 1)\n",
    "    return getProbYIsZero(np.dot(T,W)).astype(np.float64)\n",
    "    \n",
    "def getAccuracy(W, T):\n",
    "    return np.sum([T['isSpam'][i] == prediction.round() for i, prediction in enumerate(getPredictions(W,T))]) / len(T)\n",
    "\n",
    "def splitDataFrame(D, frac):\n",
    "    return (D[0: int(math.floor(len(D) * frac))], D[int(math.floor(len(D) * frac)): len(D)])\n",
    "\n",
    "def L2Regularization(W, V, penalty):\n",
    "    target = T['isSpam']\n",
    "    features = T.drop('isSpam', axis=1)\n",
    "    features.insert(0,'x_0', 1)\n",
    "    return (target - np.dot(features, W))**2 + (penalty / 2) * (W ** 2)\n",
    "    \n",
    "def logisticRegression(D, numSteps, learningRate):\n",
    "    W = np.zeros(len(D.columns))\n",
    "    ham1, ham2   = splitDataFrame(D[D['isSpam'] == 0], 0.7)\n",
    "    spam1, spam2 = splitDataFrame(D[D['isSpam'] == 1], 0.7)\n",
    "    T = ham1.append(spam1).reset_index(drop=True)\n",
    "    V = ham2.append(spam2).reset_index(drop=True)\n",
    "    for i in range(1, numSteps):\n",
    "        W += learningRate * getWeight(W,T)\n",
    "        update_progress( round(i / (numSteps - 1), 3))\n",
    "    \n",
    "    return W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent: [##########] 100%  \n",
      "Done...\n"
     ]
    }
   ],
   "source": [
    "W = logisticRegression(trainBOW, 1000, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9163179916317992"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAccuracy(W, testBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        396.983185\n",
       "1        160.249767\n",
       "2        777.700714\n",
       "3      10843.135183\n",
       "4         57.546126\n",
       "5         42.533844\n",
       "6         46.351074\n",
       "7         44.975723\n",
       "8        126.792341\n",
       "9         48.757462\n",
       "10        54.728610\n",
       "11        15.003200\n",
       "12       368.812539\n",
       "13       728.556299\n",
       "14        38.482121\n",
       "15       140.535677\n",
       "16        13.537973\n",
       "17      8447.632837\n",
       "18        30.740837\n",
       "19       231.418233\n",
       "20       637.150362\n",
       "21        50.376071\n",
       "22        47.409741\n",
       "23       864.508413\n",
       "24        60.955171\n",
       "25        40.400834\n",
       "26        96.607096\n",
       "27        49.426364\n",
       "28       501.382473\n",
       "29       102.082237\n",
       "           ...     \n",
       "433        9.139084\n",
       "434        9.106871\n",
       "435        9.716927\n",
       "436        9.955069\n",
       "437        9.588446\n",
       "438        9.658288\n",
       "439       11.165488\n",
       "440       17.482180\n",
       "441       44.035748\n",
       "442        9.079972\n",
       "443       10.561270\n",
       "444       15.676008\n",
       "445       10.695207\n",
       "446       10.456435\n",
       "447        9.733561\n",
       "448       14.228903\n",
       "449       27.205083\n",
       "450       49.311472\n",
       "451       21.260652\n",
       "452       10.336363\n",
       "453        9.671403\n",
       "454        9.595575\n",
       "455       22.801114\n",
       "456       14.915724\n",
       "457        9.012772\n",
       "458       29.425863\n",
       "459       12.144486\n",
       "460       14.391109\n",
       "461       58.170627\n",
       "462       10.706566\n",
       "Name: isSpam, Length: 463, dtype: float64"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = trainBOW\n",
    "penalty = 0.5\n",
    "target = T['isSpam']\n",
    "features = T.drop('isSpam', axis=1)\n",
    "features.insert(0,'x_0', 1)\n",
    "(target - np.dot(features, W))**2 + (penalty / 2) * np.dot(W,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0597583 , -0.19963011,  0.09378671, ...,  0.06210696,\n",
       "        0.04746371,  0.0793221 ])"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5511.0747460628145"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = trainBOW\n",
    "target = T['isSpam']\n",
    "attributes = trainBOW.drop('isSpam',axis=1)\n",
    "attributes = T.drop('isSpam', axis=1)\n",
    "attributes.insert(0, 'isSpam', 1)\n",
    "scores = np.dot(attributes, W)\n",
    "np.sum( (target * scores) - np.log(1 + np.exp(-scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463,)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
