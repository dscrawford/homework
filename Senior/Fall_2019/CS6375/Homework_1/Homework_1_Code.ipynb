{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import sys\n",
    "from itertools import chain\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lg(P)\n",
    "#  return log_2(P) if P != 0, else return 0\n",
    "def lg(P):\n",
    "    return math.log(P, 2)\n",
    "\n",
    "def Var_Impurity(K, K0, K1):\n",
    "    return (K0 * K1) / K**2\n",
    "\n",
    "def Entropy(K, K0, K1):\n",
    "    if (K0 == 0 or K1 == 0):\n",
    "        return 0\n",
    "    P_0 = K0 / K\n",
    "    P_1 = 1 - P_0\n",
    "    return -P_0 * lg(P_0) - P_1 * lg(P_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Invalid argument for learning algorithm -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "if (len(sys.argv) != 3 and len(sys.argv) != 5):\n",
    "    print('Error: Need either 2 arguments for forests and 5 for decision trees')\n",
    "    sys.exit(1)    \n",
    "fileStr              = ''\n",
    "learner              = None\n",
    "impurityFunction     = None\n",
    "impurityFunctionName = ''\n",
    "pruningAlgorithm     = []\n",
    "\n",
    "dtNames        = ['decisiontree', 'dt']\n",
    "rfNames        = ['randomforest', 'rf']\n",
    "learnerOptions = dtNames + rfNames\n",
    "\n",
    "entropyNames    = ['e', 'entropy']\n",
    "viNames         = ['varianceimpurity', 'vi']\n",
    "impurityOptions = entropyNames + viNames\n",
    "\n",
    "repNames       = ['reducederrorpruning', 'rep', 'reducederror']\n",
    "dbpNames       = ['depthbasedpruning', 'dbp', 'depthbased']\n",
    "naiveNames     = ['naive', 'n']\n",
    "pruningOptions = repNames + dbpNames + naiveNames\n",
    "\n",
    "fileStr      = sys.argv[1].lower()\n",
    "\n",
    "if (sys.argv[2].lower() in learnerOptions):\n",
    "    learner = sys.argv[2].lower()\n",
    "else:\n",
    "    print('Error: Invalid argument for learning algorithm', sys.argv[1])\n",
    "    sys.exit(1)\n",
    "\n",
    "if (learner in rfNames):\n",
    "    if (len(sys.argv) > 3):\n",
    "        print('Error: Too many arguments for random forest')\n",
    "        sys.exit(1)\n",
    "else:\n",
    "    if (len(sys.argv) < 5):\n",
    "        print('Error: Insufficient arguments for decision tree(either need more or less)')\n",
    "        sys.exit(1)\n",
    "\n",
    "    if (sys.argv[3].lower() in impurityOptions):\n",
    "        impurityFunction, impurityFunctionName = (Entropy, 'Entropy') if sys.argv[3].lower() in entropyNames else (Var_Impurity, 'Variance Impurity')\n",
    "    else:\n",
    "        print('Error: Inavlid argument for impurity function(options: \\'entropy\\' or \\'varianceimpurity\\')')\n",
    "        sys.exit(1)\n",
    "    pruningAlgorithm = sys.argv[4].replace(' ', '').lower().split(',')\n",
    "    for option in pruningAlgorithm:\n",
    "        if not option in pruningOptions:\n",
    "            print('Error: Option \\'', option, 'not valid')\n",
    "            sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner = 'e'\n",
    "#fileStr = 'c1000_d5000'\n",
    "trainFilename = \"train_\" + fileStr + \".csv\"\n",
    "validFilename = \"valid_\" + fileStr + \".csv\"\n",
    "testFilename = \"test_\"  + fileStr + \".csv\"\n",
    "train = pd.read_csv(\"./all_data/\" + trainFilename)\n",
    "valid = pd.read_csv(\"./all_data/\" + validFilename)\n",
    "test  = pd.read_csv(\"./all_data/\" + testFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns = valid.columns = test.columns = list(range(0, len(train.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H = Current impurity, X_col = column being tested, S = data set, tA = target attribute, impF = impurity function\n",
    "#Inf_Gain(H, X_col, S, tA, impF)\n",
    "#  sum <- 0\n",
    "#  unique <- unique values in X_col of S\n",
    "#  for x in unique vals\n",
    "#    Sn <- Values in S where X_col = x\n",
    "#    occurences <- number of occurences of each unique value in tA\n",
    "#    sum <- sum + entropy(occurences)\n",
    "#  return H - sum\n",
    "def Inf_Gain(H, X_col, S, tA, impF):\n",
    "    sum = 0\n",
    "    K = len(S)\n",
    "    uniqVals = S[X_col].unique()\n",
    "    for x in uniqVals:\n",
    "        Sn  = S[S[X_col] == x]\n",
    "        occurences = Sn[tA].value_counts()\n",
    "        K0 = occurences[0] if (0 in occurences.index) else 0\n",
    "        K1 = occurences[1] if (1 in occurences.index) else 0\n",
    "        Kv = K0 + K1\n",
    "        sum = sum + (Kv / K) * impF(Kv, K0, K1)\n",
    "    return H - sum;\n",
    "\n",
    "def Get_Best_Attribute(S, tA, cols, impF):\n",
    "    H = impF(len(S), len(S[S[tA] == 0]), len(S[S[tA] == 1]))\n",
    "    maxGain = (0, 0)\n",
    "    for col in cols:\n",
    "        newGain = Inf_Gain(H, col, S[[tA, col]], tA, impF)\n",
    "        maxGain = (col, newGain) if (newGain > maxGain[1])  else maxGain\n",
    "    return maxGain[0]\n",
    "\n",
    "#S = data, tA = target attribute, cols = columns to test on, \n",
    "#impF = impurity function\n",
    "#Grow_Tree(S,tA, cols, impF)\n",
    "#  s_uniq <- All unique classes in target attribute\n",
    "#  if s_uniq has only one value return a leaf with that value\n",
    "#  else\n",
    "#    x_j <- Attribute name with highest gain\n",
    "#    return node(x_j, \n",
    "#                Grow_Tree(S with x_j values == 0, tA, cols, impF),\n",
    "#                Grow_Tree(S with x_j values == 1, tA, cols, impF))\n",
    "def Grow_Tree(S, tA, cols, impF):\n",
    "    s_uniq = S[tA].unique();\n",
    "    if (len(s_uniq) == 1 and s_uniq[0] == 0):\n",
    "        return (0)\n",
    "    elif (len(s_uniq) == 1 and s_uniq[0] == 1):\n",
    "        return (1)\n",
    "    else:\n",
    "        x_j = Get_Best_Attribute(S,tA,cols[cols != tA],impF)\n",
    "        return (x_j,\n",
    "                Grow_Tree(S[S[x_j] == 0], tA, \n",
    "                          cols[cols != x_j], impF), \n",
    "                Grow_Tree(S[S[x_j] == 1], tA, \n",
    "                          cols[cols != x_j], impF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict_Tree()\n",
    "# While not at leaf:\n",
    "#  If value has no nodes on left or right, break\n",
    "#  Find attribute at current node x_j\n",
    "#  Go left if value at attribute x_j == 0, otherwise go right\n",
    "# pred = leaf.val\n",
    "def pred_tree(tree, data):\n",
    "    trav_tree = copy.copy(tree)\n",
    "    atLeaf = False\n",
    "    while True:\n",
    "        if trav_tree == 0 or trav_tree == 1:\n",
    "            break;\n",
    "        if data[trav_tree[0]] == 0:\n",
    "            trav_tree = trav_tree[1]\n",
    "        else:\n",
    "            trav_tree = trav_tree[2]\n",
    "    return trav_tree\n",
    "        \n",
    "def compare_result(tree, data, tA):\n",
    "    pred = pred_tree(tree, data)\n",
    "    return pred == data[tA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to change nodes from splits to leafs\n",
    "#Evaluate starting from nodes holding leaf nodes if they should be replaced\n",
    "#Continue upwards, with next level of nodes being nodes holding the nodes that are holding leafs\n",
    "\n",
    "#V = data set, tA = target attribute\n",
    "#Reduced_Error_Prune_Helper(V,tA, tree)\n",
    "#Start from bottom nodes and continuously replace those nodes with more general nodes.\n",
    "#currTree keeps track of branch needed to be replaced.\n",
    "#Position can help reach a node in the tree\n",
    "#treeAndAcc is a tuple with the tree on the lefthand side, and accuracy and on the right.\n",
    "def Reduced_Error_Prune(V, tA, tree):\n",
    "    treec = copy.copy(tree)\n",
    "    treeAndAcc = (tree, Get_Tree_Accuracy(V, tA, tree))\n",
    "    return Reduced_Error_Prune_Helper(V, tA, treeAndAcc, ())[0]\n",
    "\n",
    "#2^(tree height) = total node estimate in tree.\n",
    "#O(Size of the data * Numbers of nodes in the tree - Number of leafs)\n",
    "def Reduced_Error_Prune_Helper(V, tA, treeAndAcc, position):\n",
    "    currTree = Traverse_Tree(treeAndAcc[0], position)\n",
    "    \n",
    "    if (currTree == 1 or currTree == 0):\n",
    "        return treeAndAcc\n",
    "    if (type(currTree[1]) == tuple):\n",
    "        treeAndAcc = Reduced_Error_Prune_Helper(V, tA, \n",
    "                                                  treeAndAcc, \n",
    "                                                  position + (0,))\n",
    "    if (type(currTree[2]) == tuple):\n",
    "        treeAndAcc = Reduced_Error_Prune_Helper(V, tA, \n",
    "                                                  treeAndAcc, \n",
    "                                                  position + (1,))\n",
    "    \n",
    "    mcl         = Most_Common_Leaf(currTree)\n",
    "    newTree     = Set_Tree(treeAndAcc[0], mcl, copy.copy(position))\n",
    "    newAccuracy = Get_Tree_Accuracy(V, tA, newTree)\n",
    "    \n",
    "    return (newTree, newAccuracy) if newAccuracy >= treeAndAcc[1] else treeAndAcc\n",
    "\n",
    "def Depth_Based_Prune(V, tA, tree):\n",
    "    dMax        = [5,10,15,20,50,100]\n",
    "    bestTree    = copy.copy(tree)\n",
    "    maxAccuracy = Get_Tree_Accuracy(V, tA, tree)\n",
    "    \n",
    "    for depth in dMax:\n",
    "        newTree = Prune_On_Depth(tree, depth, 0)\n",
    "        newAccuracy  = Get_Tree_Accuracy(V, tA, newTree)\n",
    "        (bestTree, maxAccuracy) = (newTree, newAccuracy) if newAccuracy > maxAccuracy else (bestTree, maxAccuracy)\n",
    "    return bestTree\n",
    "\n",
    "def Prune_On_Depth(tree, dMax, depth):\n",
    "    depth += 1\n",
    "    if (tree == 1 or tree == 0):\n",
    "        return tree\n",
    "    if (depth < dMax):\n",
    "        if (type(tree[1]) == tuple):\n",
    "            tree = (tree[0], Prune_On_Depth(tree[1], dMax, depth), tree[2])\n",
    "        if (type(tree[2]) == tuple):\n",
    "            tree = (tree[0], tree[1], Prune_On_Depth(tree[2], dMax, depth))\n",
    "        return tree\n",
    "    else:\n",
    "        return Most_Common_Leaf(tree)\n",
    "    \n",
    "#Traverse and return a node in a tree based on a position array\n",
    "def Traverse_Tree(tree, position):\n",
    "    nTree = copy.copy(tree)\n",
    "    for i in position:\n",
    "        if (i == 0):\n",
    "            nTree = nTree[1]\n",
    "        else:\n",
    "            nTree = nTree[2]\n",
    "    return nTree;\n",
    "\n",
    "#Replace a node in a tree by its position and return the full tree.\n",
    "def Set_Tree(tree, newSubTree, position):\n",
    "    if (len(position) == 0):\n",
    "        return newSubTree\n",
    "    nextPos = position[0]\n",
    "    position = position[1:]\n",
    "    if (nextPos == 0):\n",
    "        return (tree[0], Set_Tree(tree[1],newSubTree,position), tree[2])\n",
    "    if (nextPos == 1):\n",
    "        return (tree[0], tree[1], Set_Tree(tree[2],newSubTree,position))\n",
    "\n",
    "#Returns most common leaf from a tree/subtree.\n",
    "def Most_Common_Leaf(tree):\n",
    "    leafs = Get_All_Leafs(tree)\n",
    "    return max(leafs, key=leafs.count)\n",
    "\n",
    "#Returns a list of all the leafs in a tree\n",
    "def Get_All_Leafs(tree):\n",
    "    if (type(tree) == tuple):\n",
    "        return Get_All_Leafs(tree[1]) + Get_All_Leafs(tree[2])\n",
    "    else:\n",
    "        if (tree == 0):\n",
    "            return [0]\n",
    "        else:\n",
    "            return [1]\n",
    "    \n",
    "#Evaluates accuracy of a tree on target attribute tA based on data D\n",
    "def Get_Tree_Accuracy(D, tA, tree):\n",
    "    results = D.apply(lambda instance: compare_result(tree, instance, tA), axis=1)\n",
    "    return len(results[results == True])/len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Analyze_Prune_Trees(V, T, tA, tree):\n",
    "    for prune in pruningAlgorithm:\n",
    "        if prune in naiveNames:\n",
    "            print(\"Accuracy with naive trees trained on \" + impurityFunctionName +\n",
    "                  \" in \" + testFilename + \":\"\n",
    "                  ,Get_Tree_Accuracy(T, tA, tree))\n",
    "        elif prune in dbpNames:\n",
    "            dbpTree = Depth_Based_Prune(V, tA,tree)\n",
    "            print(\"Accuracy with trees using depth-based pruning trained on \" + impurityFunctionName +\n",
    "                  \" in \" + testFilename + \":\"\n",
    "                  ,Get_Tree_Accuracy(T, tA, dbpTree))\n",
    "        elif prune in repNames:\n",
    "            repTree = Reduced_Error_Prune(V, tA, tree)\n",
    "            print(\"Accuracy with trees using reduced-error pruning trained on \" + impurityFunctionName +\n",
    "                  \" in \" + testFilename + \":\"\n",
    "                  ,Get_Tree_Accuracy(T, tA, repTree))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-a4d0d367c5ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 330\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if (learner in dtNames):\n",
    "    print(\"Growing tree on \" + trainFilename)\n",
    "    startTime = datetime.now()\n",
    "    tree = Grow_Tree(train, 1, train.columns, impurityFunction)\n",
    "    print(\"Time taken to grow tree: \", datetime.now() - startTime)\n",
    "    Analyze_Prune_Trees(valid, test, 1, tree)\n",
    "else:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    newTrain = train.append(valid)\n",
    "    X = newTrain.drop(columns=[1])\n",
    "    y = newTrain[1]\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "    model.fit(X, y)\n",
    "    predict = model.predict(test.drop(columns=[1]))\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    print(\"Accuracy with random forests in \" + testFilename + \":\", accuracy_score(test[1], predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
