{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#\n",
    "# LOGISTICS\n",
    "#\n",
    "#    Daniel Crawford\n",
    "#    dsc160130\n",
    "#\n",
    "# DESCRIPTION\n",
    "#\n",
    "#    Image classification in PyTorch for ImageNet reduced to 100 classes and\n",
    "#    down sampled such that the short side is 64 pixels and the long side is\n",
    "#    >= 64 pixels\n",
    "#\n",
    "#    This script achieved a best accuracy of ??.??% on epoch ?? with a learning\n",
    "#    rate at that point of ?.????? and time required for each epoch of ~ ??? s\n",
    "#\n",
    "# INSTRUCTIONS\n",
    "#\n",
    "#    1. Go to Google Colaboratory: https://colab.research.google.com/notebooks/welcome.ipynb\n",
    "#    2. File - New Python 3 notebook\n",
    "#    3. Cut and paste this file into the cell (feel free to divide into multiple cells)\n",
    "#    4. Runtime - Run all\n",
    "#\n",
    "# NOTES\n",
    "#\n",
    "#    0. For a mapping of category names to directory names see:\n",
    "#       https://gist.github.com/aaronpolhamus/964a4411c0906315deb9f4a3723aac57\n",
    "#\n",
    "#    1. The original 2012 ImageNet images are down sampled such that their short\n",
    "#       side is 64 pixels (the other side is >= 64 pixels) and only 100 of the\n",
    "#       original 1000 classes are kept.\n",
    "#\n",
    "#    2. Build and train a RegNetX image classifier modified as follows:\n",
    "#\n",
    "#       - Set stride = 1 (instead of stride = 2) in the stem\n",
    "#       - Replace the first stride = 2 down sampling building block in the\n",
    "#         original network by a stride = 1 normal building block\n",
    "#       - The fully connected layer in the decoder outputs 100 classes instead\n",
    "#         of 1000 classes\n",
    "#\n",
    "#       The original RegNetX takes in 3x224x224 input images and generates Nx7x7\n",
    "#       feature maps before the decoder, this modified RegNetX will take in\n",
    "#       3x56x56 input images and generate Nx7x7 feature maps before the decoder.\n",
    "#       For reference, an implementation of this network took ~ 112 s per epoch\n",
    "#       for training, validation and checkpoint saving on Sep 27, 2020 using a\n",
    "#       free GPU runtime in Google Colab.\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "################################################################################\n",
    "#\n",
    "# IMPORT\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn       as     nn\n",
    "import torch.optim    as     optim\n",
    "from torch.autograd import Function\n",
    "\n",
    "# torch utils\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# additional libraries\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import time\n",
    "import math\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "################################################################################\n",
    "#\n",
    "# PARAMETERS\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "# data\n",
    "DATA_DIR_1 = 'data'\n",
    "DATA_DIR_2 = 'data/imagenet64'\n",
    "DATA_DIR_TRAIN = 'data/imagenet64/train'\n",
    "DATA_DIR_TEST = 'data/imagenet64/val'\n",
    "DATA_FILE_TRAIN_1 = 'Train1.zip'\n",
    "DATA_FILE_TRAIN_2 = 'Train2.zip'\n",
    "DATA_FILE_TRAIN_3 = 'Train3.zip'\n",
    "DATA_FILE_TRAIN_4 = 'Train4.zip'\n",
    "DATA_FILE_TRAIN_5 = 'Train5.zip'\n",
    "DATA_FILE_TEST_1 = 'Val1.zip'\n",
    "DATA_URL_TRAIN_1 = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train1.zip'\n",
    "DATA_URL_TRAIN_2 = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train2.zip'\n",
    "DATA_URL_TRAIN_3 = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train3.zip'\n",
    "DATA_URL_TRAIN_4 = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train4.zip'\n",
    "DATA_URL_TRAIN_5 = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train5.zip'\n",
    "DATA_URL_TEST_1 = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Val1.zip'\n",
    "DATA_BATCH_SIZE = 256#512\n",
    "DATA_NUM_WORKERS = 4\n",
    "DATA_NUM_CHANNELS = 3\n",
    "DATA_NUM_CLASSES = 100\n",
    "DATA_RESIZE = 64\n",
    "DATA_CROP = 56\n",
    "DATA_MEAN = (0.485, 0.456, 0.406)\n",
    "DATA_STD_DEV = (0.229, 0.224, 0.225)\n",
    "\n",
    "# model\n",
    "HEAD_OUTPUT_CHANNELS = 32\n",
    "STAGE_0_CHANNELS = 24\n",
    "STAGE_1_CHANNELS = 56\n",
    "STAGE_2_CHANNELS = 152\n",
    "STAGE_3_CHANNELS = 368\n",
    "STAGE_0_BLOCKS = 1\n",
    "STAGE_1_BLOCKS = 1\n",
    "STAGE_2_BLOCKS = 4\n",
    "STAGE_3_BLOCKS = 7\n",
    "\n",
    "# training\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "\n",
    "# file\n",
    "# add file parameters here\n",
    "\n",
    "################################################################################\n",
    "#\n",
    "# DATA\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "# create a local directory structure for data storage\n",
    "if (os.path.exists(DATA_DIR_1) == False):\n",
    "    os.mkdir(DATA_DIR_1)\n",
    "if (os.path.exists(DATA_DIR_2) == False):\n",
    "    os.mkdir(DATA_DIR_2)\n",
    "if (os.path.exists(DATA_DIR_TRAIN) == False):\n",
    "    os.mkdir(DATA_DIR_TRAIN)\n",
    "if (os.path.exists(DATA_DIR_TEST) == False):\n",
    "    os.mkdir(DATA_DIR_TEST)\n",
    "\n",
    "# download data\n",
    "if (os.path.exists(DATA_FILE_TRAIN_1) == False):\n",
    "    urllib.request.urlretrieve(DATA_URL_TRAIN_1, DATA_FILE_TRAIN_1)\n",
    "if (os.path.exists(DATA_FILE_TRAIN_2) == False):\n",
    "    urllib.request.urlretrieve(DATA_URL_TRAIN_2, DATA_FILE_TRAIN_2)\n",
    "if (os.path.exists(DATA_FILE_TRAIN_3) == False):\n",
    "    urllib.request.urlretrieve(DATA_URL_TRAIN_3, DATA_FILE_TRAIN_3)\n",
    "if (os.path.exists(DATA_FILE_TRAIN_4) == False):\n",
    "    urllib.request.urlretrieve(DATA_URL_TRAIN_4, DATA_FILE_TRAIN_4)\n",
    "if (os.path.exists(DATA_FILE_TRAIN_5) == False):\n",
    "    urllib.request.urlretrieve(DATA_URL_TRAIN_5, DATA_FILE_TRAIN_5)\n",
    "if (os.path.exists(DATA_FILE_TEST_1) == False):\n",
    "    urllib.request.urlretrieve(DATA_URL_TEST_1, DATA_FILE_TEST_1)\n",
    "\n",
    "# extract data\n",
    "with zipfile.ZipFile(DATA_FILE_TRAIN_1, 'r') as zip_ref:\n",
    "    zip_ref.extractall(DATA_DIR_TRAIN)\n",
    "with zipfile.ZipFile(DATA_FILE_TRAIN_2, 'r') as zip_ref:\n",
    "    zip_ref.extractall(DATA_DIR_TRAIN)\n",
    "with zipfile.ZipFile(DATA_FILE_TRAIN_3, 'r') as zip_ref:\n",
    "    zip_ref.extractall(DATA_DIR_TRAIN)\n",
    "with zipfile.ZipFile(DATA_FILE_TRAIN_4, 'r') as zip_ref:\n",
    "    zip_ref.extractall(DATA_DIR_TRAIN)\n",
    "with zipfile.ZipFile(DATA_FILE_TRAIN_5, 'r') as zip_ref:\n",
    "    zip_ref.extractall(DATA_DIR_TRAIN)\n",
    "with zipfile.ZipFile(DATA_FILE_TEST_1, 'r') as zip_ref:\n",
    "    zip_ref.extractall(DATA_DIR_TEST)\n",
    "\n",
    "# transforms\n",
    "transform_train = transforms.Compose(\n",
    "    [transforms.RandomResizedCrop(DATA_CROP), transforms.RandomHorizontalFlip(p=0.5), transforms.ToTensor(),\n",
    "     transforms.Normalize(DATA_MEAN, DATA_STD_DEV)])\n",
    "transform_test = transforms.Compose(\n",
    "    [transforms.Resize(DATA_RESIZE), transforms.CenterCrop(DATA_CROP), transforms.ToTensor(),\n",
    "     transforms.Normalize(DATA_MEAN, DATA_STD_DEV)])\n",
    "\n",
    "# data sets\n",
    "dataset_train = torchvision.datasets.ImageFolder(DATA_DIR_TRAIN, transform=transform_train)\n",
    "dataset_test = torchvision.datasets.ImageFolder(DATA_DIR_TEST, transform=transform_test)\n",
    "\n",
    "# data loader\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=DATA_BATCH_SIZE, shuffle=True,\n",
    "                                               num_workers=DATA_NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=DATA_BATCH_SIZE, shuffle=False,\n",
    "                                              num_workers=DATA_NUM_WORKERS, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 GPU(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Train Loss:  0.000000:   0%|          | 0/504 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (24) must match the size of tensor b (32) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-11-ce7aaca0d219>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    200\u001B[0m         \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    201\u001B[0m         \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 202\u001B[0;31m         \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    203\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    204\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    720\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    721\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 722\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    723\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    724\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-11-ce7aaca0d219>\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    123\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    124\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mlayer\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menc0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 125\u001B[0;31m             \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    126\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    127\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mlayer\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menc1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    720\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    721\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 722\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    723\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    724\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-11-ce7aaca0d219>\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     48\u001B[0m                 \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m         \u001B[0;31m# return\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 50\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     51\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: The size of tensor a (24) must match the size of tensor b (32) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "#\n",
    "# NETWORK BUILDING BLOCK\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "# X block\n",
    "class XBlock(nn.Module):\n",
    "\n",
    "    # initialization\n",
    "    def __init__(self, Ni, No, Fr, Fc, Sr, Sc, G):\n",
    "        # parent initialization\n",
    "        super(XBlock, self).__init__()\n",
    "\n",
    "        self.strideIsTwo = (Sr, Sc) == (2, 2)\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Conv2d(Ni, No, (1, 1), stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(No),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(No, No, (Fr, Fc), stride=(Sr, Sc), padding=1, bias=False, groups=G),\n",
    "            nn.BatchNorm2d(No),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(No, No, (1, 1), stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(No),\n",
    "            nn.ReLU()\n",
    "        ])\n",
    "\n",
    "        if self.strideIsTwo:\n",
    "            self.conv = nn.ModuleList([\n",
    "                nn.Conv2d(Ni, No, (1, 1), stride=(Sr, Sc), padding=0, bias=False),\n",
    "                nn.BatchNorm2d(No),\n",
    "                nn.ReLU()\n",
    "            ])\n",
    "\n",
    "        self.output = nn.ReLU()\n",
    "        # operations needed to create a parameterized XBlock\n",
    "\n",
    "    # forward path\n",
    "    def forward(self, x):\n",
    "        # add your code here\n",
    "        # tie together the operations to create a parameterized XBlock\n",
    "        y = x\n",
    "        for layer in self.layers:\n",
    "            y = layer(y)\n",
    "\n",
    "        if self.strideIsTwo:\n",
    "            for layer in self.conv:\n",
    "                x = layer(x)\n",
    "        # return\n",
    "        return self.output(y + x)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "#\n",
    "# NETWORK\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "# define\n",
    "class Model(nn.Module):\n",
    "\n",
    "    # initialization\n",
    "    def __init__(self,\n",
    "                 data_num_channels,\n",
    "                 head_output_channels,\n",
    "                 stage_0_channels,\n",
    "                 stage_0_blocks,\n",
    "                 stage_1_channels,\n",
    "                 stage_1_blocks,\n",
    "                 stage_2_channels,\n",
    "                 stage_2_blocks,\n",
    "                 stage_3_channels,\n",
    "                 stage_3_blocks,\n",
    "                 data_num_classes):\n",
    "        # parent initialization\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        G = 8\n",
    "        # stem\n",
    "        self.stem = nn.ModuleList([\n",
    "            nn.Conv2d(data_num_channels, head_output_channels, (3, 3), stride=(1, 1), padding=1, bias=False),\n",
    "            nn.BatchNorm2d(head_output_channels),\n",
    "            nn.ReLU()\n",
    "        ])\n",
    "\n",
    "        self.enc0 = nn.ModuleList()\n",
    "        self.enc0.append(XBlock(head_output_channels, stage_0_channels, 3, 3, 1, 1, G))\n",
    "        for i in range(stage_0_blocks - 1):\n",
    "            self.enc0.append(XBlock(stage_0_channels, stage_0_channels, 3, 3, 1, 1, G))\n",
    "\n",
    "        self.enc1 = nn.ModuleList()\n",
    "        self.enc1.append(XBlock(stage_0_channels, stage_1_channels, 3, 3, 2, 2, G))\n",
    "        for i in range(stage_1_blocks - 1):\n",
    "            self.enc1.append(XBlock(stage_1_channels, stage_1_channels, 3, 3, 1, 1, G))\n",
    "\n",
    "        self.enc2 = nn.ModuleList()\n",
    "        self.enc2.append(XBlock(stage_1_channels, stage_2_channels, 3, 3, 2, 2, G))\n",
    "        for i in range(stage_2_blocks - 1):\n",
    "            self.enc2.append(XBlock(stage_2_channels, stage_2_channels, 3, 3, 1, 1, G))\n",
    "\n",
    "        self.enc3 = nn.ModuleList()\n",
    "        self.enc3.append(XBlock(stage_2_channels, stage_3_channels, 3, 3, 2, 2, G))\n",
    "        for i in range(stage_3_blocks - 1):\n",
    "            self.enc3.append(XBlock(stage_3_channels, stage_3_channels, 3, 3, 1, 1, G))\n",
    "\n",
    "        self.head = nn.ModuleList([\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(stage_3_channels, data_num_classes)\n",
    "        ])\n",
    "\n",
    "        self.output = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "\n",
    "    # forward path\n",
    "    def forward(self, x):\n",
    "        # add your code here\n",
    "        # tie together the operations to create a modified RegNetX-200MF\n",
    "        y = x\n",
    "        for layer in self.stem:\n",
    "            y = layer(y)\n",
    "\n",
    "        for layer in self.enc0:\n",
    "            y = layer(y)\n",
    "\n",
    "        for layer in self.enc1:\n",
    "            y = layer(y)\n",
    "\n",
    "        for layer in self.enc2:\n",
    "            y = layer(y)\n",
    "\n",
    "        for layer in self.enc3:\n",
    "            y = layer(y)\n",
    "\n",
    "        for layer in self.head:\n",
    "            y = layer(y)\n",
    "\n",
    "        # return 100 classes\n",
    "        return self.output(y)\n",
    "\n",
    "def weights_init(module):\n",
    "    if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "        nn.init.xavier_normal_(module.weight.data)\n",
    "    if isinstance(module, nn.Linear):\n",
    "        nn.init.normal_(module.weight.data)\n",
    "        nn.init.normal_(module.bias.data)\n",
    "    if isinstance(module, nn.BatchNorm2d):\n",
    "        nn.init.normal_(module.weight.data)\n",
    "        nn.init.normal_(module.bias.data)\n",
    "\n",
    "# create\n",
    "model = Model(DATA_NUM_CHANNELS,\n",
    "              HEAD_OUTPUT_CHANNELS,\n",
    "              STAGE_0_CHANNELS,\n",
    "              STAGE_0_BLOCKS,\n",
    "              STAGE_1_CHANNELS,\n",
    "              STAGE_1_BLOCKS,\n",
    "              STAGE_2_CHANNELS,\n",
    "              STAGE_2_BLOCKS,\n",
    "              STAGE_3_CHANNELS,\n",
    "              STAGE_3_BLOCKS,\n",
    "              DATA_NUM_CLASSES)\n",
    "\n",
    "#model.apply(weights_init)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# enable data parallelization for multi GPU systems\n",
    "if (torch.cuda.device_count() > 1):\n",
    "    model = nn.DataParallel(model)\n",
    "else:\n",
    "    model = model.to(device)\n",
    "\n",
    "print('Using {0:d} GPU(s)'.format(torch.cuda.device_count()), flush=True)\n",
    "\n",
    "################################################################################\n",
    "#\n",
    "# ERROR AND OPTIMIZER\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "################################################################################\n",
    "#\n",
    "# TRAINING\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "time.sleep(0.2)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss = 0\n",
    "    n = 0\n",
    "    tq = tqdm(dataloader_train)\n",
    "\n",
    "    tq.set_description('Average Train Loss: {0: 5.6f}'.format(float('0')))\n",
    "    model.train()\n",
    "    for i, data in enumerate(tq):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * len(inputs)\n",
    "        n += len(inputs)\n",
    "\n",
    "        tq.set_description('Average Train Loss: {0:5.6f}'.format(train_loss / n))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_len = 0\n",
    "        test_correct = 0\n",
    "        for data in dataloader_test:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_len += len(labels)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "    print('Test Accuracy: {0:6.2f}%'.format(test_correct / test_len * 100))\n",
    "    time.sleep(0.2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# add your code here\n",
    "# perform network training, validation and checkpoint saving\n",
    "# see previous examples in the Code directory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}