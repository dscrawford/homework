{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "import numpy as N, networkx as nx\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BELOW CODE WAS IMPLEMENTED BY John Reid in pybool package\n",
    "# https://github.com/JohnReid/pybool/blob/master/python/pybool/chow_liu_trees.py\n",
    "# The code has been pasted here because csgrads1 was having issues installing pybool\n",
    "# Add one laplace smoothing has also been included.\n",
    "\n",
    "def marginal_distribution(X, u):\n",
    "    \"\"\"\n",
    "    Return the marginal distribution for the u'th features of the data points, X.\n",
    "    \"\"\"\n",
    "    values = defaultdict(float)\n",
    "    s = 1. / len(X)\n",
    "    for x in X:\n",
    "        values[x[u]] += s\n",
    "    return values\n",
    "\n",
    "\n",
    "\n",
    "def marginal_pair_distribution(X, u, v):\n",
    "    \"\"\"\n",
    "    Return the marginal distribution for the u'th and v'th features of the data points, X.\n",
    "    \"\"\"\n",
    "    if u > v:\n",
    "        u, v = v, u\n",
    "    values = defaultdict(float)\n",
    "    s = 1. / len(X)\n",
    "    for x in X:\n",
    "        values[(x[u], x[v])] += s\n",
    "    return values\n",
    "\n",
    "\n",
    "\n",
    "def calculate_mutual_information(X, u, v):\n",
    "    \"\"\"\n",
    "    X are the data points.\n",
    "    u and v are the indices of the features to calculate the mutual information for.\n",
    "    \"\"\"\n",
    "    if u > v:\n",
    "        u, v = v, u\n",
    "    marginal_u = marginal_distribution(X, u)\n",
    "    marginal_v = marginal_distribution(X, v)\n",
    "    marginal_uv = marginal_pair_distribution(X, u, v)\n",
    "    I = 0.\n",
    "    for x_u, p_x_u in marginal_u.iteritems():\n",
    "        for x_v, p_x_v in marginal_v.iteritems():\n",
    "            if (x_u, x_v) in marginal_uv:\n",
    "                p_x_uv = marginal_uv[(x_u, x_v)]\n",
    "                I += p_x_uv * (N.log(p_x_uv) - N.log(p_x_u) - N.log(p_x_v))\n",
    "    return I\n",
    "\n",
    "\n",
    "def build_chow_liu_tree(X, n):\n",
    "    \"\"\"\n",
    "    Build a Chow-Liu tree from the data, X. n is the number of features. The weight on each edge is\n",
    "    the negative of the mutual information between those features. The tree is returned as a networkx\n",
    "    object.\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    for v in xrange(n):\n",
    "        G.add_node(v)\n",
    "        for u in xrange(v):\n",
    "            G.add_edge(u, v, weight=-calculate_mutual_information(X, u, v))\n",
    "    T = nx.minimum_spanning_tree(G)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./small-10-datasets/\"\n",
    "data_titles = ['accidents', 'baudio', 'bnetflix', 'dna', 'jester', 'kdd', 'msnbc',\n",
    "              'nltcs', 'plants', 'r52']\n",
    "test  = dict()\n",
    "train = dict()\n",
    "valid = dict()\n",
    "\n",
    "for title in data_titles:\n",
    "    test[title]  = np.loadtxt(data_dir + title + '.test.data', delimiter=',')\n",
    "    train[title] = np.loadtxt(data_dir + title + '.ts.data', delimiter=',')\n",
    "    valid[title] = np.loadtxt(data_dir + title + '.valid.data', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Likelihood\n",
    "def LL(p):\n",
    "    return np.sum(np.log2(p))\n",
    "\n",
    "def AVG_LL(P):\n",
    "    return sum([LL(p) for p in P]) / len(P)\n",
    "\n",
    "\n",
    "# How it should work: Each node should have their respective probabilities from the training set.\n",
    "# For root case, it should simple hold a table for p(x=1) and p(x=0)\n",
    "# For the directed edges, there should contain a p(x=1|y=1), p(x=1|y=0) and so on for each variable\n",
    "# Pick random node for root\n",
    "def Create_Network(MST, T):\n",
    "    n = len(MST)\n",
    "    T = np.transpose(T)\n",
    "    network = [{} for i in range(n)]\n",
    "    root = 0\n",
    "    for i in range(0,n):\n",
    "        addedNode = False\n",
    "        for j in range(0,n):\n",
    "            if (MST[j][i] != 0 and i != j):\n",
    "                p = [(sum(T[i][T[j] == 1] == 1) + 1) / (sum(T[j] == 1) + 2),\n",
    "                     (sum(T[i][T[j] == 0] == 1) + 1) / (sum(T[j] == 0) + 2)]\n",
    "                network[i].update({i : [1 - p[0], p[0], 1 - p[1], p[1]]})\n",
    "                addedNode = True\n",
    "        if (not addedNode or i == root):\n",
    "            p = (sum(T[i] == 1) + 1) / (len(T[i]) + 2)\n",
    "            network[i].update({i : [1 - p, p]})\n",
    "    return network;\n",
    "\n",
    "\n",
    "def Predict_Network(N, test):\n",
    "    all_predictions = []\n",
    "    for t in test:\n",
    "        predictions = []\n",
    "        for i in range(len(N)):\n",
    "            probs = []\n",
    "            for k in N[i].keys():\n",
    "                if(k == i):\n",
    "                    probs.append(N[i][k][0] if t[i] == 0 else N[i][k][1])\n",
    "                else:\n",
    "                    if (t[k] == 0):\n",
    "                        probs.append(N[i][k][0] if t[i] == 0 else N[i][k][1])\n",
    "                    else:\n",
    "                        probs.append(N[i][k][2] if t[i] == 0 else N[i][k][3])\n",
    "            predictions.append(np.product(probs))\n",
    "        all_predictions.append(predictions)\n",
    "    return all_predictions\n",
    "\n",
    "# n = # of columns\n",
    "def Generate_Network(n):\n",
    "    G = nx.from_numpy_array(np.array([[random.random() for i in range(n)] for j in range(n)]))\n",
    "    G = nx.to_numpy_array(nx.minimum_spanning_tree(G))\n",
    "    return Create_Network(G)\n",
    "\n",
    "def Split_Tree(T, k):\n",
    "    split = [i for i in range(0, len(T), int(len(T) / k))]\n",
    "    return [T[range(split[i],len(T) if i == k -1 else split[i+1])] for i in range(k)]\n",
    "\n",
    "# Bayesian Network, Chow-Liu Algorithm\n",
    "# Returns a data structure in the form of a Bayesian Network with probabilities pre-computed inside.\n",
    "def BN_CL(T):\n",
    "    n = len(T[0])\n",
    "    CLT = Create_Network(np.array(nx.adjacency_matrix(build_chow_liu_tree(T, n)).todense()), T)\n",
    "    return CLT\n",
    "\n",
    "# Bayesian Network, No edges Algorithm\n",
    "# Takes in a dataset of binary variables and takes a test set of binary variables.\n",
    "def BN_NE(T, test):\n",
    "    cols = np.transpose(T)\n",
    "    n    = len(cols)\n",
    "    p_1 = np.array([(sum(cols[i] == 1) + 1) / (len(cols[i]) + 2) for i in range(n)])\n",
    "    return np.array([[p_1[+i] if ti == 0 else 1 - p_1[i] for i, ti in enumerate(t)] for t in test])\n",
    "\n",
    "# Mixtures of Tree Bayesian networks using EM\n",
    "def MT_BN(T, k):\n",
    "    valid = T[range(0, int(len(T) / 10))]\n",
    "    T     = T[range(int(len(T) / 10), len(T))]\n",
    "    return EM(T,k)\n",
    "\n",
    "\n",
    "def EM(T, k):\n",
    "    T = Split_Tree(T, k)\n",
    "    r = [random.random() for i in range(k)]\n",
    "    pi = [-np.log2(i) for i in r]\n",
    "    Ns = [BN_CL(T[i]) for i in range(k)]\n",
    "    return pi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-303.09757458863464"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVG_LL(BN_NE(train['accidents'], test['accidents']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-186.3189656766254"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVG_LL(Predict_Network((BN_CL(T=train['accidents'])), test['accidents']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = MT_BN(train['accidents'][0:100], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.631221988421369"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(s[0]) / np.log(np.sum(np.exp(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3081687755833475"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
