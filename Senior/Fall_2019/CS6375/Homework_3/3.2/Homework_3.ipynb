{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "# Cross validation will be used so test set is not always defined.\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "Xtrain, ytrain = X[:60000], y[:60000]\n",
    "Xtest, ytest = X[:60000], y[:60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imageSize = 28\n",
    "numImages = 70000\n",
    "\n",
    "data = X\n",
    "data = data.reshape(numImages, imageSize, imageSize, 1)\n",
    "\n",
    "image = np.array(data[10]).squeeze()\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.conda/envs/csgrads1/lib/python2.7/site-packages/sklearn/model_selection/_split.py:2052: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/daniel/.conda/envs/csgrads1/lib/python2.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=1024, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "  max_iter=500, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=8,\n",
       "       param_grid={'kernel': ('linear', 'rbf', 'poly', 'sigmoid'), 'C': [1, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'kernel': ('linear', 'rbf', 'poly', 'sigmoid'), 'C': [1, 5, 10]}\n",
    "svc = SVC(gamma = 'scale', cache_size = 1024, max_iter = 500, shrinking = True)\n",
    "clf = GridSearchCV(estimator = svc, param_grid = parameters, n_jobs = 8)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'linear', 'C': 1}: 0.18772857142857147\n",
      "{'kernel': 'rbf', 'C': 1}: 0.023742857142857177\n",
      "{'kernel': 'poly', 'C': 1}: 0.02747142857142859\n",
      "{'kernel': 'sigmoid', 'C': 1}: 0.2566142857142857\n",
      "{'kernel': 'linear', 'C': 5}: 0.18772857142857147\n",
      "{'kernel': 'rbf', 'C': 5}: 0.018571428571428572\n",
      "{'kernel': 'poly', 'C': 5}: 0.02385714285714291\n",
      "{'kernel': 'sigmoid', 'C': 5}: 0.2572\n",
      "{'kernel': 'linear', 'C': 10}: 0.18772857142857147\n",
      "{'kernel': 'rbf', 'C': 10}: 0.01849999999999996\n",
      "{'kernel': 'poly', 'C': 10}: 0.024428571428571466\n",
      "{'kernel': 'sigmoid', 'C': 10}: 0.2581285714285714\n"
     ]
    }
   ],
   "source": [
    "for i,param in enumerate(clf.cv_results_['params']):\n",
    "    print str(param) + str(': ') + str(1 - clf.cv_results_['mean_test_score'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.conda/envs/csgrads1/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=8,\n",
       "       param_grid={'alpha': [1, 10], 'activation': ['identity', 'logistic'], 'solver': ['lbfgs', 'sgd', 'adam'], 'hidden_layer_sizes': [50, 100, 150]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'activation': ['identity', 'logistic'], \n",
    "              'hidden_layer_sizes': [50, 100, 150],\n",
    "              'solver': ['lbfgs', 'sgd', 'adam']}\n",
    "mlp  = MLPClassifier()\n",
    "clf2 = GridSearchCV(estimator = mlp, param_grid = parameters, n_jobs=8)\n",
    "clf2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=1, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=150, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1, 'activation': 'identity', 'solver': 'lbfgs', 'hidden_layer_sizes': 50}: 0.11001428571428573\n",
      "{'alpha': 1, 'activation': 'identity', 'solver': 'sgd', 'hidden_layer_sizes': 50}: 0.9013857142857142\n",
      "{'alpha': 1, 'activation': 'identity', 'solver': 'adam', 'hidden_layer_sizes': 50}: 0.09322857142857144\n",
      "{'alpha': 1, 'activation': 'identity', 'solver': 'lbfgs', 'hidden_layer_sizes': 100}: 0.1159\n",
      "{'alpha': 1, 'activation': 'identity', 'solver': 'sgd', 'hidden_layer_sizes': 100}: 0.9013857142857142\n",
      "{'alpha': 1, 'activation': 'identity', 'solver': 'adam', 'hidden_layer_sizes': 100}: 0.09172857142857138\n",
      "{'alpha': 1, 'activation': 'identity', 'solver': 'lbfgs', 'hidden_layer_sizes': 150}: 0.11699999999999999\n",
      "{'alpha': 1, 'activation': 'identity', 'solver': 'sgd', 'hidden_layer_sizes': 150}: 0.9013857142857142\n",
      "{'alpha': 1, 'activation': 'identity', 'solver': 'adam', 'hidden_layer_sizes': 150}: 0.09792857142857148\n",
      "{'alpha': 1, 'activation': 'logistic', 'solver': 'lbfgs', 'hidden_layer_sizes': 50}: 0.0753571428571429\n",
      "{'alpha': 1, 'activation': 'logistic', 'solver': 'sgd', 'hidden_layer_sizes': 50}: 0.05545714285714287\n",
      "{'alpha': 1, 'activation': 'logistic', 'solver': 'adam', 'hidden_layer_sizes': 50}: 0.06857142857142862\n",
      "{'alpha': 1, 'activation': 'logistic', 'solver': 'lbfgs', 'hidden_layer_sizes': 100}: 0.05335714285714288\n",
      "{'alpha': 1, 'activation': 'logistic', 'solver': 'sgd', 'hidden_layer_sizes': 100}: 0.047042857142857164\n",
      "{'alpha': 1, 'activation': 'logistic', 'solver': 'adam', 'hidden_layer_sizes': 100}: 0.06278571428571433\n",
      "{'alpha': 1, 'activation': 'logistic', 'solver': 'lbfgs', 'hidden_layer_sizes': 150}: 0.047900000000000054\n",
      "{'alpha': 1, 'activation': 'logistic', 'solver': 'sgd', 'hidden_layer_sizes': 150}: 0.043571428571428594\n",
      "{'alpha': 1, 'activation': 'logistic', 'solver': 'adam', 'hidden_layer_sizes': 150}: 0.05905714285714281\n"
     ]
    }
   ],
   "source": [
    "for i,param in enumerate(clf2.cv_results_['params']):\n",
    "    if (param['alpha'] == 1):\n",
    "        print str(param) + str(': ') + str(1 - clf2.cv_results_['mean_test_score'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1      113356.3281            1.92m\n",
      "         2       97944.6355            1.85m\n",
      "         3       85869.1441            1.85m\n",
      "         4       77129.0787            1.82m\n",
      "         5       69491.5135            1.81m\n",
      "         6       63201.9173            1.78m\n",
      "         7       57708.4426            1.77m\n",
      "         8       53023.7948            1.76m\n",
      "         9       49090.7302            1.74m\n",
      "        10       45483.5991            1.73m\n",
      "        20       24984.9501            1.54m\n",
      "        30       16653.3883            1.34m\n",
      "        40       12289.6831            1.14m\n",
      "        50        9674.0922           56.87s\n",
      "        60        7940.1540           45.27s\n",
      "        70        6524.2215           33.79s\n",
      "        80        5514.1111           22.37s\n",
      "        90        4718.1250           11.12s\n",
      "       100        4073.8652            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      117577.7541            1.28m\n",
      "         2      103050.9481            1.27m\n",
      "         3       92789.0571            1.26m\n",
      "         4       84119.1013            1.24m\n",
      "         5       77067.8124            1.21m\n",
      "         6       71061.1938            1.21m\n",
      "         7       65762.3832            1.20m\n",
      "         8       61263.7975            1.19m\n",
      "         9       57445.3814            1.17m\n",
      "        10       53751.1413            1.16m\n",
      "        20       32172.0376            1.03m\n",
      "        30       22652.7651           53.88s\n",
      "        40       17538.1986           46.13s\n",
      "        50       14303.7932           38.30s\n",
      "        60       12196.6992           30.47s\n",
      "        70       10547.7670           22.74s\n",
      "        80        9330.5096           15.07s\n",
      "        90        8377.0571            7.48s\n",
      "       100        7547.1850            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      123148.2118           51.06s\n",
      "         2      110220.5025           50.26s\n",
      "         3      101182.9204           49.86s\n",
      "         4       93735.9018           49.50s\n",
      "         5       87161.5632           48.28s\n",
      "         6       81534.1122           47.63s\n",
      "         7       76794.7678           47.01s\n",
      "         8       72321.3073           46.61s\n",
      "         9       67912.3240           46.23s\n",
      "        10       63935.5189           45.80s\n",
      "        20       41216.7704           40.60s\n",
      "        30       30314.0578           35.75s\n",
      "        40       24298.6240           30.68s\n",
      "        50       20619.7891           25.46s\n",
      "        60       18138.4165           20.27s\n",
      "        70       16197.1216           15.17s\n",
      "        80       14674.4136           10.07s\n",
      "        90       13388.8346            5.02s\n",
      "       100       12391.1737            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      127650.1555           32.78s\n",
      "         2      119025.3196           31.43s\n",
      "         3      110949.0546           30.49s\n",
      "         4      105347.8092           30.04s\n",
      "         5       99421.6309           29.71s\n",
      "         6       94969.8000           29.34s\n",
      "         7       89862.7746           29.07s\n",
      "         8       85798.2534           28.66s\n",
      "         9       82017.5584           28.38s\n",
      "        10       78751.9927           28.11s\n",
      "        20       55795.0356           24.99s\n",
      "        30       43391.5216           22.02s\n",
      "        40       36072.3257           18.90s\n",
      "        50       31311.9392           15.65s\n",
      "        60       27887.5448           12.48s\n",
      "        70       25234.2623            9.33s\n",
      "        80       23237.4340            6.19s\n",
      "        90       21613.1132            3.08s\n",
      "       100       20246.7960            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      133735.7297           17.04s\n",
      "         2      129074.0418           16.85s\n",
      "         3      124220.7969           16.78s\n",
      "         4      120601.0783           16.67s\n",
      "         5      117662.9347           16.52s\n",
      "         6      114418.2301           16.35s\n",
      "         7      110963.3983           16.17s\n",
      "         8      108060.6489           16.00s\n",
      "         9      105216.9284           15.85s\n",
      "        10      102565.1574           15.69s\n",
      "        20       82356.7009           13.90s\n",
      "        30       69291.7091           12.14s\n",
      "        40       59829.0921           10.41s\n",
      "        50       52821.5650            8.68s\n",
      "        60       47592.1495            6.94s\n",
      "        70       43856.8466            5.21s\n",
      "        80       40749.4273            3.47s\n",
      "        90       38148.1591            1.74s\n",
      "       100       35942.5775            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='mse', init=None, learning_rate=0.1,\n",
       "              loss='deviance', max_depth=1, max_features='sqrt',\n",
       "              max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "              min_impurity_split=None, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, n_iter_no_change=None, presort='auto',\n",
       "              random_state=None, subsample=1.0, tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gbc = GradientBoostingClassifier(loss='deviance',criterion='mse', verbose=1, max_depth=5, max_features = 'sqrt')\n",
    "gbc.fit(Xtrain, ytrain)\n",
    "\n",
    "gbc2 = GradientBoostingClassifier(loss='deviance',criterion='mse', verbose=1, max_depth=4, max_features = 'sqrt')\n",
    "gbc2.fit(Xtrain, ytrain)\n",
    "\n",
    "gbc3 = GradientBoostingClassifier(loss='deviance',criterion='mse', verbose=1, max_depth=3, max_features = 'sqrt')\n",
    "gbc3.fit(Xtrain, ytrain)\n",
    "\n",
    "gbc4 = GradientBoostingClassifier(loss='deviance',criterion='mse', verbose=1, max_depth=2,\n",
    "                                  max_features = 'sqrt')\n",
    "gbc4.fit(Xtrain, ytrain)\n",
    "\n",
    "gbc5 = GradientBoostingClassifier(loss='deviance',criterion='mse', verbose=1, max_depth=1,\n",
    "                                  max_features = 'sqrt')\n",
    "gbc5.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1      113757.6654            1.95m\n",
      "         2       98148.7608            1.92m\n",
      "         3       86856.3373            1.90m\n",
      "         4       77554.2726            1.88m\n",
      "         5       70076.6664            1.86m\n",
      "         6       63443.5502            1.84m\n",
      "         7       58313.2630            1.82m\n",
      "         8       53670.9498            1.80m\n",
      "         9       49478.2138            1.78m\n",
      "        10       45758.3282            1.76m\n",
      "        20       24746.4737            1.57m\n",
      "        30       16501.3014            1.37m\n",
      "        40       12135.2746            1.17m\n",
      "        50        9524.9027           58.35s\n",
      "        60        7700.6021           46.47s\n",
      "        70        6451.1502           34.51s\n",
      "        80        5486.6132           22.87s\n",
      "        90        4668.4608           11.37s\n",
      "       100        3991.7886            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      116822.4131            1.27m\n",
      "         2      102068.1027            1.24m\n",
      "         3       91950.1068            1.22m\n",
      "         4       83427.9102            1.22m\n",
      "         5       76493.6791            1.21m\n",
      "         6       70518.9926            1.20m\n",
      "         7       65316.1944            1.19m\n",
      "         8       60823.1052            1.17m\n",
      "         9       56683.1501            1.17m\n",
      "        10       53085.6493            1.15m\n",
      "        20       31606.8494            1.04m\n",
      "        30       22263.6391           54.37s\n",
      "        40       17299.5515           46.53s\n",
      "        50       14142.5275           38.69s\n",
      "        60       12030.7821           30.77s\n",
      "        70       10426.2926           22.94s\n",
      "        80        9145.9467           15.21s\n",
      "        90        8137.6510            7.58s\n",
      "       100        7377.8225            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      120544.3460           51.64s\n",
      "         2      109021.1666           50.61s\n",
      "         3       99683.1329           49.18s\n",
      "         4       91862.3749           48.37s\n",
      "         5       85421.2303           48.00s\n",
      "         6       80020.5637           47.43s\n",
      "         7       75275.7680           46.81s\n",
      "         8       70798.3563           46.31s\n",
      "         9       66769.9608           45.98s\n",
      "        10       63394.0194           45.48s\n",
      "        20       40991.4303           40.46s\n",
      "        30       30313.7029           35.65s\n",
      "        40       24417.0952           30.38s\n",
      "        50       20661.3660           25.24s\n",
      "        60       18133.0308           20.12s\n",
      "        70       16171.5166           15.04s\n",
      "        80       14649.7362           10.00s\n",
      "        90       13356.9214            4.99s\n",
      "       100       12335.7592            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      126731.6494           29.03s\n",
      "         2      118429.1818           29.93s\n",
      "         3      111305.5706           29.54s\n",
      "         4      105038.8603           29.29s\n",
      "         5       98737.7700           29.46s\n",
      "         6       94353.8475           29.43s\n",
      "         7       90266.6538           28.99s\n",
      "         8       85995.5719           28.56s\n",
      "         9       81946.8030           28.34s\n",
      "        10       78778.0156           28.15s\n",
      "        20       55852.0636           25.10s\n",
      "        30       43001.5595           22.05s\n",
      "        40       35733.4554           19.03s\n",
      "        50       30949.8043           15.85s\n",
      "        60       27626.5887           12.60s\n",
      "        70       25088.1800            9.43s\n",
      "        80       23003.9694            6.28s\n",
      "        90       21447.2356            3.13s\n",
      "       100       20107.1229            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      135422.5729            1.91m\n",
      "         2      132946.1296            1.89m\n",
      "         3      130615.9579            1.87m\n",
      "         4      128219.4399            1.86m\n",
      "         5      126029.5298            1.84m\n",
      "         6      123901.3245            1.83m\n",
      "         7      121870.9280            1.82m\n",
      "         8      119870.5677            1.79m\n",
      "         9      117983.8705            1.77m\n",
      "        10      116116.6196            1.75m\n",
      "        20      100492.5071            1.56m\n",
      "        30       88638.4497            1.36m\n",
      "        40       78945.6284            1.17m\n",
      "        50       70976.0317           58.34s\n",
      "        60       64334.5968           46.62s\n",
      "        70       58671.3405           34.90s\n",
      "        80       53802.6119           23.24s\n",
      "        90       49482.9132           11.63s\n",
      "       100       45730.8050            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.01, loss='deviance', max_depth=5,\n",
       "              max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc6 = GradientBoostingClassifier(loss='deviance',criterion='friedman_mse', verbose=1, max_depth=5,\n",
    "                                  max_features = 'sqrt')\n",
    "gbc6.fit(Xtrain, ytrain)\n",
    "\n",
    "gbc7 = GradientBoostingClassifier(loss='deviance',criterion='friedman_mse', verbose=1, max_depth=4,\n",
    "                                  max_features = 'sqrt')\n",
    "gbc7.fit(Xtrain, ytrain)\n",
    "\n",
    "gbc8 = GradientBoostingClassifier(loss='deviance',criterion='friedman_mse', verbose=1, max_depth=3,\n",
    "                                  max_features = 'sqrt')\n",
    "gbc8.fit(Xtrain, ytrain)\n",
    "\n",
    "gbc9 = GradientBoostingClassifier(loss='deviance',criterion='friedman_mse', verbose=1, max_depth=2,\n",
    "                                  max_features = 'sqrt')\n",
    "gbc9.fit(Xtrain, ytrain)\n",
    "\n",
    "gbc10 = GradientBoostingClassifier(loss='deviance',criterion='friedman_mse', verbose=1, max_depth=5,\n",
    "                                  learning_rate = 0.01, max_features = 'sqrt')\n",
    "gbc10.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse with max depth 5 error rate: 0.011349999999999971\n",
      "mse with max depth 4 error rate: 0.02915000000000001\n",
      "mse with max depth 3 error rate: 0.05078333333333329\n",
      "mae with max depth 2 error rate: 0.08538333333333337\n",
      "mae with max depth 1 error rate: 0.1471\n",
      "friedman_mse with max depth 5 error rate: 0.010433333333333294\n",
      "friedman_mse with max depth 4 error rate: 0.0275333333333333\n",
      "friedman_mse with max depth 3 error rate: 0.05091666666666672\n",
      "friedman_mse with max depth 2 error rate: 0.08520000000000005\n",
      "friedman_mse with max depth 5 and learning rate 0.01 error rate: 0.07448333333333335\n"
     ]
    }
   ],
   "source": [
    "print 'mse with max depth 5 error rate: ' + str(1 - gbc.score(Xtest,ytest))\n",
    "print 'mse with max depth 4 error rate: ' + str(1 - gbc2.score(Xtest,ytest))\n",
    "print 'mse with max depth 3 error rate: ' + str(1 - gbc3.score(Xtest,ytest))\n",
    "print 'mae with max depth 2 error rate: ' + str(1 - gbc4.score(Xtest,ytest))\n",
    "print 'mae with max depth 1 error rate: ' + str(1 - gbc5.score(Xtest,ytest))\n",
    "print 'friedman_mse with max depth 5 error rate: ' + str(1 - gbc6.score(Xtest,ytest))\n",
    "print 'friedman_mse with max depth 4 error rate: ' + str(1 - gbc7.score(Xtest,ytest))\n",
    "print 'friedman_mse with max depth 3 error rate: ' + str(1 - gbc8.score(Xtest,ytest))\n",
    "print 'friedman_mse with max depth 2 error rate: ' + str(1 - gbc9.score(Xtest,ytest))\n",
    "print 'friedman_mse with max depth 5 and learning rate 0.01 error rate: ' + str(1 - gbc10.score(Xtest,ytest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
